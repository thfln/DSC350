{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49440513-02b6-4915-94ed-b96bfaa3e02e",
   "metadata": {},
   "source": [
    "# DSC350 - Week 4 - Exercise 4.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6c6ca1d-823d-4c58-937f-10091b564153",
   "metadata": {},
   "source": [
    "============================================\n",
    "; Title: Assignment 4.2\n",
    "; Author: Stefanie Molin\n",
    "; Date: 26 June 2024\n",
    "; Modified By: Tyler Heflin\n",
    "; Description: This program demonstrates the use of Python to use CSV\n",
    "; files, append them into a single dataframe, and perform queries\n",
    "; on the newly created dataset.\n",
    ";=========================================== */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10561c-ab60-43db-ab9d-14acbbdf72b5",
   "metadata": {},
   "source": [
    "We begin the exercises this week by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5ed149-853e-4822-89d7-ad1a3703f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9781dd8-fe93-4cc3-81cb-0afd3e8c48fa",
   "metadata": {},
   "source": [
    "## Hands-On Data Analysis with Python (2nd Edition): Page 190, Exercises 1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caabfa8-e13b-4133-936a-e9e9ae47f156",
   "metadata": {},
   "source": [
    "**1. We want to look at data for the Facebook, Apple, Amazon, Netflix, and Google (FAANG) stocks, but we were given each as a separate CSV file (obtained using the \"stock_analysis\" package we will build in Chapter 7, Financial Analysis - Bitcoin and the Stock Market). Combine them into a single file and store the dataframe of the FAANG data as faang for the rest of the exercises:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476bdd26-1ea3-40c9-99b1-83a89c5da985",
   "metadata": {},
   "source": [
    "a) Read in the \"aapl.csv\", \"amzn.csv\", \"fb.csv\", \"goog.csv\", and \"nflx.csv\" files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9604969e-73d4-44e9-b24c-94162312ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context of aapl.csv:\n",
      "           date       high        low       open      close       volume\n",
      "0    2018-01-02  43.075001  42.314999  42.540001  43.064999  102223600.0\n",
      "1    2018-01-03  43.637501  42.990002  43.132500  43.057499  118071600.0\n",
      "2    2018-01-04  43.367500  43.020000  43.134998  43.257500   89738400.0\n",
      "3    2018-01-05  43.842499  43.262501  43.360001  43.750000   94640000.0\n",
      "4    2018-01-08  43.902500  43.482498  43.587502  43.587502   82271200.0\n",
      "..          ...        ...        ...        ...        ...          ...\n",
      "246  2018-12-24  37.887501  36.647499  37.037498  36.707500  148676800.0\n",
      "247  2018-12-26  39.307499  36.680000  37.075001  39.292500  234330000.0\n",
      "248  2018-12-27  39.192501  37.517502  38.959999  39.037498  212468400.0\n",
      "249  2018-12-28  39.630001  38.637501  39.375000  39.057499  169165600.0\n",
      "250  2018-12-31  39.840000  39.119999  39.632500  39.435001  140014000.0\n",
      "\n",
      "[251 rows x 6 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of amzn.csv:\n",
      "           date         high          low         open        close    volume\n",
      "0    2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   2694500\n",
      "1    2018-01-03  1205.489990  1188.300049  1188.300049  1204.199951   3108800\n",
      "2    2018-01-04  1215.869995  1204.660034  1205.000000  1209.589966   3022100\n",
      "3    2018-01-05  1229.140015  1210.000000  1217.510010  1229.140015   3544700\n",
      "4    2018-01-08  1253.079956  1232.030029  1236.000000  1246.869995   4279500\n",
      "..          ...          ...          ...          ...          ...       ...\n",
      "246  2018-12-24  1396.030029  1307.000000  1346.000000  1343.959961   7220000\n",
      "247  2018-12-26  1473.160034  1363.010010  1368.890015  1470.900024  10411800\n",
      "248  2018-12-27  1469.000000  1390.310059  1454.199951  1461.640015   9722000\n",
      "249  2018-12-28  1513.469971  1449.000000  1473.349976  1478.020020   8829000\n",
      "250  2018-12-31  1520.760010  1487.000000  1510.800049  1501.969971   6954500\n",
      "\n",
      "[251 rows x 6 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of fb.csv:\n",
      "           date        high         low        open       close    volume\n",
      "0    2018-01-02  181.580002  177.550003  177.679993  181.419998  18151900\n",
      "1    2018-01-03  184.779999  181.330002  181.880005  184.669998  16886600\n",
      "2    2018-01-04  186.210007  184.100006  184.899994  184.330002  13880900\n",
      "3    2018-01-05  186.899994  184.929993  185.589996  186.850006  13574500\n",
      "4    2018-01-08  188.899994  186.330002  187.199997  188.279999  17994700\n",
      "..          ...         ...         ...         ...         ...       ...\n",
      "246  2018-12-24  129.740005  123.019997  123.099998  124.059998  22066000\n",
      "247  2018-12-26  134.240005  125.889999  126.000000  134.179993  39723400\n",
      "248  2018-12-27  134.990005  129.669998  132.440002  134.520004  31202500\n",
      "249  2018-12-28  135.919998  132.199997  135.339996  133.199997  22627600\n",
      "250  2018-12-31  134.639999  129.949997  134.449997  131.089996  24625300\n",
      "\n",
      "[251 rows x 6 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of goog.csv:\n",
      "           date         high          low         open        close   volume\n",
      "0    2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000  1237600\n",
      "1    2018-01-03  1086.290039  1063.209961  1064.310059  1082.479980  1430200\n",
      "2    2018-01-04  1093.569946  1084.001953  1088.000000  1086.400024  1004600\n",
      "3    2018-01-05  1104.250000  1092.000000  1094.000000  1102.229980  1279100\n",
      "4    2018-01-08  1111.270020  1101.619995  1102.229980  1106.939941  1047600\n",
      "..          ...          ...          ...          ...          ...      ...\n",
      "246  2018-12-24  1003.539978   970.109985   973.900024   976.219971  1590300\n",
      "247  2018-12-26  1040.000000   983.000000   989.010010  1039.459961  2373300\n",
      "248  2018-12-27  1043.890015   997.000000  1017.150024  1043.880005  2109800\n",
      "249  2018-12-28  1055.560059  1033.099976  1049.619995  1037.079956  1414800\n",
      "250  2018-12-31  1052.699951  1023.590027  1050.959961  1035.609985  1493300\n",
      "\n",
      "[251 rows x 6 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of nflx.csv:\n",
      "           date        high         low        open       close    volume\n",
      "0    2018-01-02  201.649994  195.419998  196.100006  201.070007  10966900\n",
      "1    2018-01-03  206.210007  201.500000  202.050003  205.050003   8591400\n",
      "2    2018-01-04  207.050003  204.000000  206.199997  205.630005   6029600\n",
      "3    2018-01-05  210.020004  205.589996  207.250000  209.990005   7033200\n",
      "4    2018-01-08  212.500000  208.440002  210.020004  212.050003   5580200\n",
      "..          ...         ...         ...         ...         ...       ...\n",
      "246  2018-12-24  250.649994  233.679993  242.000000  233.880005   9547600\n",
      "247  2018-12-26  254.500000  231.229996  233.919998  253.669998  14402700\n",
      "248  2018-12-27  255.589996  240.100006  250.110001  255.570007  12235200\n",
      "249  2018-12-28  261.910004  249.800003  257.940002  256.079987  10992800\n",
      "250  2018-12-31  270.100006  260.000000  260.160004  267.660004  13508900\n",
      "\n",
      "[251 rows x 6 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the files are downloaded\n",
    "download_path = os.path.expanduser(r'C:\\Users\\thefli0\\Downloads')\n",
    "\n",
    "# Define the list of CSV files\n",
    "csv_files = ['aapl.csv', 'amzn.csv', 'fb.csv', 'goog.csv', 'nflx.csv']\n",
    "\n",
    "# Loop through the files, read the contents, print results\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        file_path = os.path.join(download_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Context of {file}:\")\n",
    "        print(df)\n",
    "        # Use separator for clarity\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019508b2-5938-45fb-bb91-dd333fab9059",
   "metadata": {},
   "source": [
    "b) Add a column to each dataframe, called \"ticker\", indicating the ticker symbol it is for (Apple's is AAPL, for example); this is how you look up a stock. In this case, the filenames happen to be the ticker symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671cfb37-0783-4db9-92ff-7d64922464ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context of aapl.csv:\n",
      "           date       high        low       open      close       volume  \\\n",
      "0    2018-01-02  43.075001  42.314999  42.540001  43.064999  102223600.0   \n",
      "1    2018-01-03  43.637501  42.990002  43.132500  43.057499  118071600.0   \n",
      "2    2018-01-04  43.367500  43.020000  43.134998  43.257500   89738400.0   \n",
      "3    2018-01-05  43.842499  43.262501  43.360001  43.750000   94640000.0   \n",
      "4    2018-01-08  43.902500  43.482498  43.587502  43.587502   82271200.0   \n",
      "..          ...        ...        ...        ...        ...          ...   \n",
      "246  2018-12-24  37.887501  36.647499  37.037498  36.707500  148676800.0   \n",
      "247  2018-12-26  39.307499  36.680000  37.075001  39.292500  234330000.0   \n",
      "248  2018-12-27  39.192501  37.517502  38.959999  39.037498  212468400.0   \n",
      "249  2018-12-28  39.630001  38.637501  39.375000  39.057499  169165600.0   \n",
      "250  2018-12-31  39.840000  39.119999  39.632500  39.435001  140014000.0   \n",
      "\n",
      "    ticker  \n",
      "0     AAPL  \n",
      "1     AAPL  \n",
      "2     AAPL  \n",
      "3     AAPL  \n",
      "4     AAPL  \n",
      "..     ...  \n",
      "246   AAPL  \n",
      "247   AAPL  \n",
      "248   AAPL  \n",
      "249   AAPL  \n",
      "250   AAPL  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of amzn.csv:\n",
      "           date         high          low         open        close    volume  \\\n",
      "0    2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   2694500   \n",
      "1    2018-01-03  1205.489990  1188.300049  1188.300049  1204.199951   3108800   \n",
      "2    2018-01-04  1215.869995  1204.660034  1205.000000  1209.589966   3022100   \n",
      "3    2018-01-05  1229.140015  1210.000000  1217.510010  1229.140015   3544700   \n",
      "4    2018-01-08  1253.079956  1232.030029  1236.000000  1246.869995   4279500   \n",
      "..          ...          ...          ...          ...          ...       ...   \n",
      "246  2018-12-24  1396.030029  1307.000000  1346.000000  1343.959961   7220000   \n",
      "247  2018-12-26  1473.160034  1363.010010  1368.890015  1470.900024  10411800   \n",
      "248  2018-12-27  1469.000000  1390.310059  1454.199951  1461.640015   9722000   \n",
      "249  2018-12-28  1513.469971  1449.000000  1473.349976  1478.020020   8829000   \n",
      "250  2018-12-31  1520.760010  1487.000000  1510.800049  1501.969971   6954500   \n",
      "\n",
      "    ticker  \n",
      "0     AMZN  \n",
      "1     AMZN  \n",
      "2     AMZN  \n",
      "3     AMZN  \n",
      "4     AMZN  \n",
      "..     ...  \n",
      "246   AMZN  \n",
      "247   AMZN  \n",
      "248   AMZN  \n",
      "249   AMZN  \n",
      "250   AMZN  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of fb.csv:\n",
      "           date        high         low        open       close    volume  \\\n",
      "0    2018-01-02  181.580002  177.550003  177.679993  181.419998  18151900   \n",
      "1    2018-01-03  184.779999  181.330002  181.880005  184.669998  16886600   \n",
      "2    2018-01-04  186.210007  184.100006  184.899994  184.330002  13880900   \n",
      "3    2018-01-05  186.899994  184.929993  185.589996  186.850006  13574500   \n",
      "4    2018-01-08  188.899994  186.330002  187.199997  188.279999  17994700   \n",
      "..          ...         ...         ...         ...         ...       ...   \n",
      "246  2018-12-24  129.740005  123.019997  123.099998  124.059998  22066000   \n",
      "247  2018-12-26  134.240005  125.889999  126.000000  134.179993  39723400   \n",
      "248  2018-12-27  134.990005  129.669998  132.440002  134.520004  31202500   \n",
      "249  2018-12-28  135.919998  132.199997  135.339996  133.199997  22627600   \n",
      "250  2018-12-31  134.639999  129.949997  134.449997  131.089996  24625300   \n",
      "\n",
      "    ticker  \n",
      "0       FB  \n",
      "1       FB  \n",
      "2       FB  \n",
      "3       FB  \n",
      "4       FB  \n",
      "..     ...  \n",
      "246     FB  \n",
      "247     FB  \n",
      "248     FB  \n",
      "249     FB  \n",
      "250     FB  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of goog.csv:\n",
      "           date         high          low         open        close   volume  \\\n",
      "0    2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000  1237600   \n",
      "1    2018-01-03  1086.290039  1063.209961  1064.310059  1082.479980  1430200   \n",
      "2    2018-01-04  1093.569946  1084.001953  1088.000000  1086.400024  1004600   \n",
      "3    2018-01-05  1104.250000  1092.000000  1094.000000  1102.229980  1279100   \n",
      "4    2018-01-08  1111.270020  1101.619995  1102.229980  1106.939941  1047600   \n",
      "..          ...          ...          ...          ...          ...      ...   \n",
      "246  2018-12-24  1003.539978   970.109985   973.900024   976.219971  1590300   \n",
      "247  2018-12-26  1040.000000   983.000000   989.010010  1039.459961  2373300   \n",
      "248  2018-12-27  1043.890015   997.000000  1017.150024  1043.880005  2109800   \n",
      "249  2018-12-28  1055.560059  1033.099976  1049.619995  1037.079956  1414800   \n",
      "250  2018-12-31  1052.699951  1023.590027  1050.959961  1035.609985  1493300   \n",
      "\n",
      "    ticker  \n",
      "0     GOOG  \n",
      "1     GOOG  \n",
      "2     GOOG  \n",
      "3     GOOG  \n",
      "4     GOOG  \n",
      "..     ...  \n",
      "246   GOOG  \n",
      "247   GOOG  \n",
      "248   GOOG  \n",
      "249   GOOG  \n",
      "250   GOOG  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Context of nflx.csv:\n",
      "           date        high         low        open       close    volume  \\\n",
      "0    2018-01-02  201.649994  195.419998  196.100006  201.070007  10966900   \n",
      "1    2018-01-03  206.210007  201.500000  202.050003  205.050003   8591400   \n",
      "2    2018-01-04  207.050003  204.000000  206.199997  205.630005   6029600   \n",
      "3    2018-01-05  210.020004  205.589996  207.250000  209.990005   7033200   \n",
      "4    2018-01-08  212.500000  208.440002  210.020004  212.050003   5580200   \n",
      "..          ...         ...         ...         ...         ...       ...   \n",
      "246  2018-12-24  250.649994  233.679993  242.000000  233.880005   9547600   \n",
      "247  2018-12-26  254.500000  231.229996  233.919998  253.669998  14402700   \n",
      "248  2018-12-27  255.589996  240.100006  250.110001  255.570007  12235200   \n",
      "249  2018-12-28  261.910004  249.800003  257.940002  256.079987  10992800   \n",
      "250  2018-12-31  270.100006  260.000000  260.160004  267.660004  13508900   \n",
      "\n",
      "    ticker  \n",
      "0     NFLX  \n",
      "1     NFLX  \n",
      "2     NFLX  \n",
      "3     NFLX  \n",
      "4     NFLX  \n",
      "..     ...  \n",
      "246   NFLX  \n",
      "247   NFLX  \n",
      "248   NFLX  \n",
      "249   NFLX  \n",
      "250   NFLX  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of CSV files with the corresponding ticker symbols\n",
    "csv_files = {\n",
    "    'aapl.csv': 'AAPL', \n",
    "    'amzn.csv': 'AMZN', \n",
    "    'fb.csv': 'FB', \n",
    "    'goog.csv': 'GOOG', \n",
    "    'nflx.csv': 'NFLX'\n",
    "}\n",
    "\n",
    "# Loop through the files, read the contents, add the ticker column, print results\n",
    "for file, ticker in csv_files.items():\n",
    "    try:\n",
    "        file_path = os.path.join(download_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add ticker column\n",
    "        df['ticker'] = ticker\n",
    "        print(f\"Context of {file}:\")\n",
    "        print(df)\n",
    "        \n",
    "        # Use separator for clarity\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7cf206-46b4-4288-87a2-8851ec7426e7",
   "metadata": {},
   "source": [
    "c) Append them together into a single dataframe. <br>\n",
    "d) Save the result in a CSV file called, \"faang.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b505ebb-f14e-450b-8274-03fcd495f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context of aapl.csv:\n",
      "           date       high        low       open      close       volume  \\\n",
      "0    2018-01-02  43.075001  42.314999  42.540001  43.064999  102223600.0   \n",
      "1    2018-01-03  43.637501  42.990002  43.132500  43.057499  118071600.0   \n",
      "2    2018-01-04  43.367500  43.020000  43.134998  43.257500   89738400.0   \n",
      "3    2018-01-05  43.842499  43.262501  43.360001  43.750000   94640000.0   \n",
      "4    2018-01-08  43.902500  43.482498  43.587502  43.587502   82271200.0   \n",
      "..          ...        ...        ...        ...        ...          ...   \n",
      "246  2018-12-24  37.887501  36.647499  37.037498  36.707500  148676800.0   \n",
      "247  2018-12-26  39.307499  36.680000  37.075001  39.292500  234330000.0   \n",
      "248  2018-12-27  39.192501  37.517502  38.959999  39.037498  212468400.0   \n",
      "249  2018-12-28  39.630001  38.637501  39.375000  39.057499  169165600.0   \n",
      "250  2018-12-31  39.840000  39.119999  39.632500  39.435001  140014000.0   \n",
      "\n",
      "    ticker  \n",
      "0     AAPL  \n",
      "1     AAPL  \n",
      "2     AAPL  \n",
      "3     AAPL  \n",
      "4     AAPL  \n",
      "..     ...  \n",
      "246   AAPL  \n",
      "247   AAPL  \n",
      "248   AAPL  \n",
      "249   AAPL  \n",
      "250   AAPL  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "Context of amzn.csv:\n",
      "           date         high          low         open        close    volume  \\\n",
      "0    2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   2694500   \n",
      "1    2018-01-03  1205.489990  1188.300049  1188.300049  1204.199951   3108800   \n",
      "2    2018-01-04  1215.869995  1204.660034  1205.000000  1209.589966   3022100   \n",
      "3    2018-01-05  1229.140015  1210.000000  1217.510010  1229.140015   3544700   \n",
      "4    2018-01-08  1253.079956  1232.030029  1236.000000  1246.869995   4279500   \n",
      "..          ...          ...          ...          ...          ...       ...   \n",
      "246  2018-12-24  1396.030029  1307.000000  1346.000000  1343.959961   7220000   \n",
      "247  2018-12-26  1473.160034  1363.010010  1368.890015  1470.900024  10411800   \n",
      "248  2018-12-27  1469.000000  1390.310059  1454.199951  1461.640015   9722000   \n",
      "249  2018-12-28  1513.469971  1449.000000  1473.349976  1478.020020   8829000   \n",
      "250  2018-12-31  1520.760010  1487.000000  1510.800049  1501.969971   6954500   \n",
      "\n",
      "    ticker  \n",
      "0     AMZN  \n",
      "1     AMZN  \n",
      "2     AMZN  \n",
      "3     AMZN  \n",
      "4     AMZN  \n",
      "..     ...  \n",
      "246   AMZN  \n",
      "247   AMZN  \n",
      "248   AMZN  \n",
      "249   AMZN  \n",
      "250   AMZN  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "Context of fb.csv:\n",
      "           date        high         low        open       close    volume  \\\n",
      "0    2018-01-02  181.580002  177.550003  177.679993  181.419998  18151900   \n",
      "1    2018-01-03  184.779999  181.330002  181.880005  184.669998  16886600   \n",
      "2    2018-01-04  186.210007  184.100006  184.899994  184.330002  13880900   \n",
      "3    2018-01-05  186.899994  184.929993  185.589996  186.850006  13574500   \n",
      "4    2018-01-08  188.899994  186.330002  187.199997  188.279999  17994700   \n",
      "..          ...         ...         ...         ...         ...       ...   \n",
      "246  2018-12-24  129.740005  123.019997  123.099998  124.059998  22066000   \n",
      "247  2018-12-26  134.240005  125.889999  126.000000  134.179993  39723400   \n",
      "248  2018-12-27  134.990005  129.669998  132.440002  134.520004  31202500   \n",
      "249  2018-12-28  135.919998  132.199997  135.339996  133.199997  22627600   \n",
      "250  2018-12-31  134.639999  129.949997  134.449997  131.089996  24625300   \n",
      "\n",
      "    ticker  \n",
      "0       FB  \n",
      "1       FB  \n",
      "2       FB  \n",
      "3       FB  \n",
      "4       FB  \n",
      "..     ...  \n",
      "246     FB  \n",
      "247     FB  \n",
      "248     FB  \n",
      "249     FB  \n",
      "250     FB  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "Context of goog.csv:\n",
      "           date         high          low         open        close   volume  \\\n",
      "0    2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000  1237600   \n",
      "1    2018-01-03  1086.290039  1063.209961  1064.310059  1082.479980  1430200   \n",
      "2    2018-01-04  1093.569946  1084.001953  1088.000000  1086.400024  1004600   \n",
      "3    2018-01-05  1104.250000  1092.000000  1094.000000  1102.229980  1279100   \n",
      "4    2018-01-08  1111.270020  1101.619995  1102.229980  1106.939941  1047600   \n",
      "..          ...          ...          ...          ...          ...      ...   \n",
      "246  2018-12-24  1003.539978   970.109985   973.900024   976.219971  1590300   \n",
      "247  2018-12-26  1040.000000   983.000000   989.010010  1039.459961  2373300   \n",
      "248  2018-12-27  1043.890015   997.000000  1017.150024  1043.880005  2109800   \n",
      "249  2018-12-28  1055.560059  1033.099976  1049.619995  1037.079956  1414800   \n",
      "250  2018-12-31  1052.699951  1023.590027  1050.959961  1035.609985  1493300   \n",
      "\n",
      "    ticker  \n",
      "0     GOOG  \n",
      "1     GOOG  \n",
      "2     GOOG  \n",
      "3     GOOG  \n",
      "4     GOOG  \n",
      "..     ...  \n",
      "246   GOOG  \n",
      "247   GOOG  \n",
      "248   GOOG  \n",
      "249   GOOG  \n",
      "250   GOOG  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "Context of nflx.csv:\n",
      "           date        high         low        open       close    volume  \\\n",
      "0    2018-01-02  201.649994  195.419998  196.100006  201.070007  10966900   \n",
      "1    2018-01-03  206.210007  201.500000  202.050003  205.050003   8591400   \n",
      "2    2018-01-04  207.050003  204.000000  206.199997  205.630005   6029600   \n",
      "3    2018-01-05  210.020004  205.589996  207.250000  209.990005   7033200   \n",
      "4    2018-01-08  212.500000  208.440002  210.020004  212.050003   5580200   \n",
      "..          ...         ...         ...         ...         ...       ...   \n",
      "246  2018-12-24  250.649994  233.679993  242.000000  233.880005   9547600   \n",
      "247  2018-12-26  254.500000  231.229996  233.919998  253.669998  14402700   \n",
      "248  2018-12-27  255.589996  240.100006  250.110001  255.570007  12235200   \n",
      "249  2018-12-28  261.910004  249.800003  257.940002  256.079987  10992800   \n",
      "250  2018-12-31  270.100006  260.000000  260.160004  267.660004  13508900   \n",
      "\n",
      "    ticker  \n",
      "0     NFLX  \n",
      "1     NFLX  \n",
      "2     NFLX  \n",
      "3     NFLX  \n",
      "4     NFLX  \n",
      "..     ...  \n",
      "246   NFLX  \n",
      "247   NFLX  \n",
      "248   NFLX  \n",
      "249   NFLX  \n",
      "250   NFLX  \n",
      "\n",
      "[251 rows x 7 columns]\n",
      "Combined DataFrame saved as C:\\Users\\thefli0\\Downloads\\faang.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the list of CSV files with the corresponding ticker symbols\n",
    "csv_files = {\n",
    "    'aapl.csv': 'AAPL', \n",
    "    'amzn.csv': 'AMZN', \n",
    "    'fb.csv': 'FB', \n",
    "    'goog.csv': 'GOOG', \n",
    "    'nflx.csv': 'NFLX'\n",
    "}\n",
    "\n",
    "# Create a list to hold each dataframe\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the files, read the contents, add the ticker column, print results\n",
    "for file, ticker in csv_files.items():\n",
    "    try:\n",
    "        file_path = os.path.join(download_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add ticker column\n",
    "        df['ticker'] = ticker\n",
    "        print(f\"Context of {file}:\")\n",
    "        print(df)\n",
    "        \n",
    "        # Append dataframe to the previously created list\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Concat all dataframes into a single dataframe\n",
    "faang_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save result to a new CSV file\n",
    "faang_csv_path = os.path.join(download_path, 'faang.csv')\n",
    "faang_df.to_csv(faang_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved as {faang_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327d73e-3db5-439a-8d54-988304f390a8",
   "metadata": {},
   "source": [
    "**2. With faang, use type conversion to cast the values of the \"date\" column into datetimes and the \"volume\" column into integers. Then, sort by \"date\" and \"ticker\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59413b1-11ff-49b5-a3f6-eac4b2c9b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date         high          low         open        close  \\\n",
      "0    2018-01-02    43.075001    42.314999    42.540001    43.064999   \n",
      "251  2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   \n",
      "502  2018-01-02   181.580002   177.550003   177.679993   181.419998   \n",
      "753  2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000   \n",
      "1004 2018-01-02   201.649994   195.419998   196.100006   201.070007   \n",
      "...         ...          ...          ...          ...          ...   \n",
      "250  2018-12-31    39.840000    39.119999    39.632500    39.435001   \n",
      "501  2018-12-31  1520.760010  1487.000000  1510.800049  1501.969971   \n",
      "752  2018-12-31   134.639999   129.949997   134.449997   131.089996   \n",
      "1003 2018-12-31  1052.699951  1023.590027  1050.959961  1035.609985   \n",
      "1254 2018-12-31   270.100006   260.000000   260.160004   267.660004   \n",
      "\n",
      "         volume ticker  \n",
      "0     102223600   AAPL  \n",
      "251     2694500   AMZN  \n",
      "502    18151900     FB  \n",
      "753     1237600   GOOG  \n",
      "1004   10966900   NFLX  \n",
      "...         ...    ...  \n",
      "250   140014000   AAPL  \n",
      "501     6954500   AMZN  \n",
      "752    24625300     FB  \n",
      "1003    1493300   GOOG  \n",
      "1254   13508900   NFLX  \n",
      "\n",
      "[1255 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the files are downloaded\n",
    "download_path = os.path.expanduser(r'C:\\Users\\thefli0\\Downloads')\n",
    "\n",
    "# Define the path for the CSV file\n",
    "faang_csv_path = os.path.join(download_path, 'faang.csv')\n",
    "\n",
    "# Read the file to a dataframe\n",
    "df = pd.read_csv(faang_csv_path)\n",
    "\n",
    "# Convert 'date' column to new format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Convert 'volume column to new format\n",
    "df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "# Sort dataframe by 'date' and 'ticker'\n",
    "sorted_df = df.sort_values(by=['date', 'ticker'])\n",
    "# Print sorted dataframe\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f7d42-e294-4249-b1bb-e8340feb02ee",
   "metadata": {},
   "source": [
    "**3. Find the seven rows in \"faang\" with the lowest value for \"volume\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b2cf0d5-71f7-4b1f-97b9-6be3bdba2fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date         high          low         open        close  volume  \\\n",
      "879 2018-07-03  1135.819946  1100.020020  1135.819946  1102.890015  679000   \n",
      "979 2018-11-23  1037.589966  1022.398987  1030.000000  1023.880005  691500   \n",
      "852 2018-05-24  1080.469971  1066.150024  1079.000000  1079.239990  766800   \n",
      "883 2018-07-10  1159.589966  1149.589966  1156.979980  1152.839966  798400   \n",
      "905 2018-08-09  1255.541992  1246.010010  1249.900024  1249.099976  848600   \n",
      "912 2018-08-20  1211.000000  1194.625977  1205.020020  1207.770020  870800   \n",
      "914 2018-08-22  1211.839966  1199.000000  1200.000000  1207.329956  887400   \n",
      "\n",
      "    ticker  \n",
      "879   GOOG  \n",
      "979   GOOG  \n",
      "852   GOOG  \n",
      "883   GOOG  \n",
      "905   GOOG  \n",
      "912   GOOG  \n",
      "914   GOOG  \n"
     ]
    }
   ],
   "source": [
    "# Define the path where the files are downloaded\n",
    "download_path = os.path.expanduser(r'C:\\Users\\thefli0\\Downloads')\n",
    "\n",
    "# Define the path for the CSV file\n",
    "faang_csv_path = os.path.join(download_path, 'faang.csv')\n",
    "\n",
    "# Read the file to a dataframe\n",
    "df = pd.read_csv(faang_csv_path)\n",
    "\n",
    "# Convert 'date' column to new format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Convert 'volume column to new format\n",
    "df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "# Sort dataframe by 'date' and 'ticker'\n",
    "sorted_df = df.sort_values(by=['date', 'ticker'])\n",
    "\n",
    "# Find the seven rows with the loest volume for 'volume'\n",
    "lowest_volume_rows = sorted_df.nsmallest(7, 'volume')\n",
    "\n",
    "# Print rows\n",
    "print(lowest_volume_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e502910-ca57-4061-81ac-0d1d12325071",
   "metadata": {},
   "source": [
    "**4. Right now, the data is somewhere between long and wide format. Use \"melt()\" to make it completely long format. Hint: \"date\" and \"ticker\" are our ID variables (they uniquely identify each row). We need to melt the rest so that we don't have separate columns for \"open\", \"high\", \"low\", \"close\", and \"volume\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fa2721-467f-452f-b7eb-c80f61f0b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date ticker variable         value\n",
      "0     2018-01-02   AAPL     high  4.307500e+01\n",
      "1     2018-01-03   AAPL     high  4.363750e+01\n",
      "2     2018-01-04   AAPL     high  4.336750e+01\n",
      "3     2018-01-05   AAPL     high  4.384250e+01\n",
      "4     2018-01-08   AAPL     high  4.390250e+01\n",
      "...          ...    ...      ...           ...\n",
      "6270  2018-12-24   NFLX   volume  9.547600e+06\n",
      "6271  2018-12-26   NFLX   volume  1.440270e+07\n",
      "6272  2018-12-27   NFLX   volume  1.223520e+07\n",
      "6273  2018-12-28   NFLX   volume  1.099280e+07\n",
      "6274  2018-12-31   NFLX   volume  1.350890e+07\n",
      "\n",
      "[6275 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the files are downloaded\n",
    "download_path = os.path.expanduser(r'C:\\Users\\thefli0\\Downloads')\n",
    "\n",
    "# Define the path for the CSV file\n",
    "faang_csv_path = os.path.join(download_path, 'faang.csv')\n",
    "\n",
    "# Read the file to a dataframe\n",
    "df = pd.read_csv(faang_csv_path)\n",
    "\n",
    "# Melt dataframe to long format\n",
    "long_format_df = pd.melt(df, id_vars=['date', 'ticker'],\n",
    "                         var_name='variable', value_name='value')\n",
    "\n",
    "# Print long format dataframe\n",
    "print(long_format_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc70c6-4454-4c5b-89f3-fba4159702b3",
   "metadata": {},
   "source": [
    "**5. Suppose we found out that on July 26, 2018 there was a glitch in how the data was recorded. How should we handle this? Note that there is no coding required for this exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74a6ff-b974-4462-9a13-3e3154373aba",
   "metadata": {},
   "source": [
    "1. To ensure that data accuracy and integrity is maintained, there are several steps that need to occur that include appropriate assessment, correction, documentation, and communication. We first need to identify the impact; which data points were affected and are there any specific patterns. Next, we can assess the extent; are only the entries on that day affected or are subsequent entries affected as well. Then, we refer to documentation to understand what the correct data should look like. After doing this, we can contact the product owner to correct the data and document any corrections that were made. To ensure transparency, these changes should be communicated to everyone that is using the data. The final steps include reviewing and validating the entire dataset to ensure the glitch was fully addressed and implementing preventative measures to mitigate the possibility of future issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
