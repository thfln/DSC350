{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0c148-16ce-42c2-a6d3-c33f84842843",
   "metadata": {},
   "source": [
    "# DSC350 - Week 3 - Exercise 3.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e18703db-81a3-47bf-b130-defc81177877",
   "metadata": {},
   "source": [
    "============================================\n",
    "; Title: Assignment 3.2\n",
    "; Author: Stefanie Molin\n",
    "; Date: 19 June 2024\n",
    "; Modified By: Tyler Heflin\n",
    "; Description: This program demonstrates the uses of the pandas library \n",
    "; in conjunction with Python.\n",
    ";=========================================== */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b77254-f42f-49dc-ae58-c0053b061010",
   "metadata": {},
   "source": [
    "We begin the exercises this week by importing the necessary libraries to complete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe83e94-f2c1-4b4a-b30e-6bd068ff042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from pandas.io.parsers import read_csv\n",
    "import quandl\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a1a23-35ff-4ceb-9dcc-baefb97a3155",
   "metadata": {},
   "source": [
    "## Hands-On Data Analysis (2nd Edition) page 111, Exercises 1-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b934e-add9-462b-b852-aec2788c4e6a",
   "metadata": {},
   "source": [
    "Using the data/parsed.csv file and the materials from this chapter, complete the following exercises to practice your *pandas* skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ff69a-524c-4985-9a05-04a4713a57ec",
   "metadata": {},
   "source": [
    "**1. Find the 95th percentile of earthquake magnitude in Japan using the *mb* magnitude type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35462133-00ed-4098-90f8-896a129a8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95th percentile of earthquake magnitudes in Japan using the 'mb' magnitude type is 4.90\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\parsed.csv')\n",
    "\n",
    "# Filter the created dataframe for entries in Japan and 'mb' type\n",
    "japan_mb_df = df[(df['parsed_place'] == 'Japan') & (df['magType'] == 'mb')].copy()\n",
    "\n",
    "# Convert 'magnitude' column to numeric, force errors to NaN\n",
    "japan_mb_df['mag'] = pd.to_numeric(japan_mb_df['mag'], errors='coerce')\n",
    "# Drop rows with NaN values\n",
    "japan_mb_df = japan_mb_df.dropna(subset=['mag'])\n",
    "\n",
    "# Calculate 95th percentile\n",
    "percentile_95 = japan_mb_df['mag'].quantile(0.95)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The 95th percentile of earthquake magnitudes in Japan using the 'mb' magnitude type is {percentile_95:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ebaec-d50a-48f7-a51a-f440e4e81e09",
   "metadata": {},
   "source": [
    "**2. Find the percentage of earthquakes in Indonesia that were coupled with tsunamis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42de582-ed42-43ae-8691-24efa21dba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of earthquakes in Indonesia that also had a tsunami is 23.13%\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\parsed.csv')\n",
    "\n",
    "# Filter the created dataframe for entries in Indonesia\n",
    "indonesia_df = df[df['parsed_place'].str.contains('Indonesia', na=False)]\n",
    "\n",
    "# Count the total number od earthquakes in Indonesia\n",
    "total_earthquakes = len(indonesia_df)\n",
    "\n",
    "# Filter entries for tsunami where 1 (indicating tsunami occurred\n",
    "tsunami_events = len(indonesia_df[indonesia_df['tsunami'] == 1])\n",
    "\n",
    "# Calculate percentage of earthquakes with tsunamis\n",
    "if total_earthquakes > 0:\n",
    "    tsunami_percentage = (tsunami_events / total_earthquakes) * 100\n",
    "else:\n",
    "    tsunami_percentage = 0\n",
    "\n",
    "# Display results\n",
    "print(f\"The percentage of earthquakes in Indonesia that also had a tsunami is {tsunami_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052fa51-ee9f-4322-869a-290378a4c10d",
   "metadata": {},
   "source": [
    "**3. Calculate summary statistics for earthquakes in Nevada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cb5107-1bd3-4a82-af13-ab5403a2190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Earthquakes in Nevada:\n",
      "             cdi        dmin       felt         gap         mag   mmi  \\\n",
      "count  14.000000  647.000000  14.000000  647.000000  647.000000  1.00   \n",
      "mean    2.421429    0.163155   2.500000  154.436615    0.437311  2.84   \n",
      "std     0.514675    0.161793   4.783787   69.474945    0.653397   NaN   \n",
      "min     2.000000    0.001000   1.000000   29.140000   -0.500000  2.84   \n",
      "25%     2.000000    0.053000   1.000000   97.295000   -0.100000  2.84   \n",
      "50%     2.200000    0.109000   1.000000  150.040000    0.300000  2.84   \n",
      "75%     3.000000    0.223000   1.000000  200.515000    0.800000  2.84   \n",
      "max     3.300000    1.414000  19.000000  355.910000    2.900000  2.84   \n",
      "\n",
      "              nst         rms         sig          time  tsunami     tz  \\\n",
      "count  647.000000  647.000000  647.000000  6.470000e+02    647.0  647.0   \n",
      "mean    12.704791    0.140627    9.146832  1.538318e+12      0.0 -480.0   \n",
      "std     10.052695    0.056765   17.939055  5.954980e+08      0.0    0.0   \n",
      "min      3.000000    0.000500    0.000000  1.537247e+12      0.0 -480.0   \n",
      "25%      6.000000    0.104400    0.000000  1.537859e+12      0.0 -480.0   \n",
      "50%      9.000000    0.142900    1.000000  1.538286e+12      0.0 -480.0   \n",
      "75%     16.000000    0.181050   10.000000  1.538824e+12      0.0 -480.0   \n",
      "max     61.000000    0.340000  129.000000  1.539461e+12      0.0 -480.0   \n",
      "\n",
      "            updated  \n",
      "count  6.470000e+02  \n",
      "mean   1.538409e+12  \n",
      "std    5.991682e+08  \n",
      "min    1.537323e+12  \n",
      "25%    1.537928e+12  \n",
      "50%    1.538428e+12  \n",
      "75%    1.538878e+12  \n",
      "max    1.539483e+12  \n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\parsed.csv')\n",
    "\n",
    "# Filter the created dataframe for entries with 'Nevada' and 'earthquake'\n",
    "nevada_earthquakes_df = df[(df['type'] == 'earthquake') & (df['parsed_place'].str.contains('Nevada', na=False))]\n",
    "\n",
    "# Generate summary statistics for filtered dataframe\n",
    "summary_statistics = nevada_earthquakes_df.describe()\n",
    "\n",
    "# Display results\n",
    "print(\"Summary Statistics for Earthquakes in Nevada:\")\n",
    "print(summary_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea1c0f-d809-407a-b718-8fa276605567",
   "metadata": {},
   "source": [
    "**4. Add a column indicating whether the earthquake happened in a country or US state that is on the Ring of Fire. Use Alaska, Antarctica (look for Antarctic), Bolivia, California, Canada, Chile, Costa Rica, Ecuador, Fiji, Guatemala, Indonesia, Japan, Kermadec Islands, Mexico (be careful not to select New Mexico), New Zealand, Peru, Philippines, Russia, Taiwan, Tonga, and Washington.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb720439-b57b-4cb2-b721-5cbe2491381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  alert  cdi      code                                             detail  \\\n",
      "0   NaN  NaN  37389218  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "1   NaN  NaN  37389202  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "2   NaN  4.4  37389194  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "3   NaN  NaN  37389186  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "4   NaN  NaN  73096941  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "\n",
      "       dmin  felt    gap           ids   mag magType  ...           time  \\\n",
      "0  0.008693   NaN   85.0  ,ci37389218,  1.35      ml  ...  1539475168010   \n",
      "1  0.020030   NaN   79.0  ,ci37389202,  1.29      ml  ...  1539475129610   \n",
      "2  0.021370  28.0   21.0  ,ci37389194,  3.42      ml  ...  1539475062610   \n",
      "3  0.026180   NaN   39.0  ,ci37389186,  0.44      ml  ...  1539474978070   \n",
      "4  0.077990   NaN  192.0  ,nc73096941,  2.16      md  ...  1539474716050   \n",
      "\n",
      "                           title  tsunami        type  \\\n",
      "0  M 1.4 - 9km NE of Aguanga, CA        0  earthquake   \n",
      "1  M 1.3 - 9km NE of Aguanga, CA        0  earthquake   \n",
      "2  M 3.4 - 8km NE of Aguanga, CA        0  earthquake   \n",
      "3  M 0.4 - 9km NE of Aguanga, CA        0  earthquake   \n",
      "4  M 2.2 - 10km NW of Avenal, CA        0  earthquake   \n",
      "\n",
      "                                               types     tz        updated  \\\n",
      "0         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475395144   \n",
      "1         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475253925   \n",
      "2  ,dyfi,focal-mechanism,geoserve,nearby-cities,o... -480.0  1539536756176   \n",
      "3         ,geoserve,nearby-cities,origin,phase-data, -480.0  1539475196167   \n",
      "4  ,geoserve,nearby-cities,origin,phase-data,scit... -480.0  1539477547926   \n",
      "\n",
      "                                                 url  parsed_place  \\\n",
      "0  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
      "1  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
      "2  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
      "3  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
      "4  https://earthquake.usgs.gov/earthquakes/eventp...    California   \n",
      "\n",
      "  Ring of Fire  \n",
      "0            1  \n",
      "1            1  \n",
      "2            1  \n",
      "3            1  \n",
      "4            1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\parsed.csv')\n",
    "\n",
    "# Define list of \"Ring of Fire\" locations\n",
    "ring_of_fire_locations = ['Alaska', 'Pacific-Antartic Ridge', 'Western Indian-Arctic Ridge',\n",
    "                         'Bolivia', 'California', 'Canada', 'Chile', 'Costa Rica', 'Ecuador',\n",
    "                         'Fiji', 'Guatemala', 'Indonesia', 'Japan', 'Kermadec Islands', 'Mexico', \n",
    "                         'New Zealand', 'Peru', 'Philippines', 'Russia', 'Taiwan', 'Tonga',\n",
    "                         'Washington']\n",
    "\n",
    "# Create new column with default value of 0\n",
    "df['Ring of Fire'] = 0\n",
    "\n",
    "# Set 'Ring of Fire' column to 1 for rows that meet specified criteria\n",
    "df.loc[(df['type'] == 'earthquake') & (df['parsed_place'].isin(ring_of_fire_locations)), 'Ring of Fire'] = 1\n",
    "\n",
    "# Save to new, updated file\n",
    "df.to_csv(r'C:\\Users\\thefli0\\Downloads\\updated_parsed.csv', index=False)\n",
    "\n",
    "# Display first few rows of updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169f576-6843-451e-bc3b-9bc247128a85",
   "metadata": {},
   "source": [
    "**5. Calculate the number of earthquakes in the Ring of Fire locations and the number outside of them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce0478a-d724-41e4-be18-60354eac668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of earthquakes in the Ring of Fire locations: 7000\n",
      "Number of earthquakes outside the Ring of Fire locations: 2081\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\updated_parsed.csv')\n",
    "\n",
    "# Calculate the number of earthquakes in Ring of Fire locations\n",
    "num_ring_of_fire_earthquakes = df[df['Ring of Fire'] == 1].shape[0]\n",
    "\n",
    "# Calculate the number of earthquakes outside of Ring of Fire locations\n",
    "num_non_ring_of_fire_earthquakes = df[(df['type'] == 'earthquake') & (df['Ring of Fire'] == 0)].shape[0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of earthquakes in the Ring of Fire locations: {num_ring_of_fire_earthquakes}\")\n",
    "print(f\"Number of earthquakes outside the Ring of Fire locations: {num_non_ring_of_fire_earthquakes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ee6c8-dc35-4438-a992-3935f10a5632",
   "metadata": {},
   "source": [
    "**6. Find the tsunami count along the Ring of Fire.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0291a4-6b67-4e63-9091-dcd1dafa71c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of tsunamis in the Ring of Fire locations: 45\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as a dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\updated_parsed.csv')\n",
    "\n",
    "# Filter the datafram for rows where 'Ring of Fire' equals 1 and 'tsunami' equals 1\n",
    "tsunami_in_ring_of_fire_df = df[(df['Ring of Fire'] == 1) & (df['tsunami'] == 1)]\n",
    "\n",
    "# Count number of tsunamis in filtered dataframe\n",
    "num_tsunamis_in_ring_of_fire = tsunami_in_ring_of_fire_df.shape[0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Total count of tsunamis in the Ring of Fire locations: {num_tsunamis_in_ring_of_fire}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152da9f-9a62-4293-8050-1e15ac247104",
   "metadata": {},
   "source": [
    "## Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf5b99-f3dd-4c63-9e28-838c869e00ca",
   "metadata": {},
   "source": [
    "**Using the file WHO_first9cols.csv, complete the following tasks:**\n",
    " - Load the data into a DataFrame and print the results\n",
    " - Query the number of rows\n",
    " - Print the column headers\n",
    " - Print the data types\n",
    " - Print the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0d6008-1a7d-470a-a2db-70dbc65c40f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Top 5 rows:\n",
      "        Country  CountryID  Continent  Adolescent fertility rate (%)  \\\n",
      "0  Afghanistan          1          1                          151.0   \n",
      "1      Albania          2          2                           27.0   \n",
      "2      Algeria          3          3                            6.0   \n",
      "3      Andorra          4          2                            NaN   \n",
      "4       Angola          5          3                          146.0   \n",
      "\n",
      "   Adult literacy rate (%)  \\\n",
      "0                     28.0   \n",
      "1                     98.7   \n",
      "2                     69.9   \n",
      "3                      NaN   \n",
      "4                     67.4   \n",
      "\n",
      "   Gross national income per capita (PPP international $)  \\\n",
      "0                                                NaN        \n",
      "1                                             6000.0        \n",
      "2                                             5940.0        \n",
      "3                                                NaN        \n",
      "4                                             3890.0        \n",
      "\n",
      "   Net primary school enrolment ratio female (%)  \\\n",
      "0                                            NaN   \n",
      "1                                           93.0   \n",
      "2                                           94.0   \n",
      "3                                           83.0   \n",
      "4                                           49.0   \n",
      "\n",
      "   Net primary school enrolment ratio male (%)  \\\n",
      "0                                          NaN   \n",
      "1                                         94.0   \n",
      "2                                         96.0   \n",
      "3                                         83.0   \n",
      "4                                         51.0   \n",
      "\n",
      "   Population (in thousands) total  \n",
      "0                          26088.0  \n",
      "1                           3172.0  \n",
      "2                          33351.0  \n",
      "3                             74.0  \n",
      "4                          16557.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as the dataframe\n",
    "df = read_csv(r\"C:\\Users\\thefli0\\Downloads\\WHO_first9cols.csv\")\n",
    "\n",
    "# Display the first five rows with headers\n",
    "print(\"Dataframe Top 5 rows:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f809eb-27bc-447f-b6cf-298569c8918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      " 202\n",
      "\n",
      "\n",
      "Column Headers:\n",
      " Index(['Country', 'CountryID', 'Continent', 'Adolescent fertility rate (%)',\n",
      "       'Adult literacy rate (%)',\n",
      "       'Gross national income per capita (PPP international $)',\n",
      "       'Net primary school enrolment ratio female (%)',\n",
      "       'Net primary school enrolment ratio male (%)',\n",
      "       'Population (in thousands) total'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Data types:\n",
      " Country                                                    object\n",
      "CountryID                                                   int64\n",
      "Continent                                                   int64\n",
      "Adolescent fertility rate (%)                             float64\n",
      "Adult literacy rate (%)                                   float64\n",
      "Gross national income per capita (PPP international $)    float64\n",
      "Net primary school enrolment ratio female (%)             float64\n",
      "Net primary school enrolment ratio male (%)               float64\n",
      "Population (in thousands) total                           float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Index:\n",
      " RangeIndex(start=0, stop=202, step=1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displays the number of rows contained within\n",
    "print(\"Length:\\n\", len(df))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Displays column headers\n",
    "print(\"Column Headers:\\n\", df.columns)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Displays the data types\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Displays the index\n",
    "print(\"Index:\\n\", df.index)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d69891-d525-4ff1-bfb2-68e9f4c6b54b",
   "metadata": {},
   "source": [
    "## Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b341a-67e9-4498-9d90-3578fcf21155",
   "metadata": {},
   "source": [
    "**Using the same file, select the \"Country\" column and return its data type along with the series shape, index, values, and name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d69da9b-4d32-4957-a3dd-cc2c6aced2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type df:\n",
      " <class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "Type country col:\n",
      " <class 'pandas.core.series.Series'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe for \"Country\"\n",
    "country_col = df[\"Country\"]\n",
    "\n",
    "# Display the data type\n",
    "print(\"Type df:\\n\", type(df), \"\\n\")\n",
    "print(\"Type country col:\\n\", type(country_col), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195ec1f3-2658-46d1-9dcd-a4bccb8de233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series shape:\n",
      " (202,) \n",
      "\n",
      "Series index:\n",
      " RangeIndex(start=0, stop=202, step=1) \n",
      "\n",
      "Series values:\n",
      " ['Afghanistan' 'Albania' 'Algeria' 'Andorra' 'Angola'\n",
      " 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Australia' 'Austria'\n",
      " 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus'\n",
      " 'Belgium' 'Belize' 'Benin' 'Bermuda' 'Bhutan' 'Bolivia'\n",
      " 'Bosnia and Herzegovina' 'Botswana' 'Brazil' 'Brunei Darussalam'\n",
      " 'Bulgaria' 'Burkina Faso' 'Burundi' 'Cambodia' 'Cameroon' 'Canada'\n",
      " 'Cape Verde' 'Central African Republic' 'Chad' 'Chile' 'China' 'Colombia'\n",
      " 'Comoros' 'Congo, Dem. Rep.' 'Congo, Rep.' 'Cook Islands' 'Costa Rica'\n",
      " \"Cote d'Ivoire\" 'Croatia' 'Cuba' 'Cyprus' 'Czech Republic' 'Denmark'\n",
      " 'Djibouti' 'Dominica' 'Dominican Republic' 'Ecuador' 'Egypt'\n",
      " 'El Salvador' 'Equatorial Guinea' 'Eritrea' 'Estonia' 'Ethiopia' 'Fiji'\n",
      " 'Finland' 'France' 'French Polynesia' 'Gabon' 'Gambia' 'Georgia'\n",
      " 'Germany' 'Ghana' 'Greece' 'Grenada' 'Guatemala' 'Guinea' 'Guinea-Bissau'\n",
      " 'Guyana' 'Haiti' 'Honduras' 'Hong Kong, China' 'Hungary' 'Iceland'\n",
      " 'India' 'Indonesia' 'Iran (Islamic Republic of)' 'Iraq' 'Ireland'\n",
      " 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan' 'Kenya'\n",
      " 'Kiribati' 'Korea, Dem. Rep.' 'Korea, Rep.' 'Kuwait' 'Kyrgyzstan'\n",
      " \"Lao People's Democratic Republic\" 'Latvia' 'Lebanon' 'Lesotho' 'Liberia'\n",
      " 'Libyan Arab Jamahiriya' 'Lithuania' 'Luxembourg' 'Macao, China'\n",
      " 'Macedonia' 'Madagascar' 'Malawi' 'Malaysia' 'Maldives' 'Mali' 'Malta'\n",
      " 'Marshall Islands' 'Mauritania' 'Mauritius' 'Mexico'\n",
      " 'Micronesia (Federated States of)' 'Moldova' 'Monaco' 'Mongolia'\n",
      " 'Montenegro' 'Morocco' 'Mozambique' 'Myanmar' 'Namibia' 'Nauru' 'Nepal'\n",
      " 'Netherlands' 'Netherlands Antilles' 'New Caledonia' 'New Zealand'\n",
      " 'Nicaragua' 'Niger' 'Nigeria' 'Niue' 'Norway' 'Oman' 'Pakistan' 'Palau'\n",
      " 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines' 'Poland'\n",
      " 'Portugal' 'Puerto Rico' 'Qatar' 'Romania' 'Russia' 'Rwanda'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and the Grenadines'\n",
      " 'Samoa' 'San Marino' 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal'\n",
      " 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore' 'Slovakia' 'Slovenia'\n",
      " 'Solomon Islands' 'Somalia' 'South Africa' 'Spain' 'Sri Lanka' 'Sudan'\n",
      " 'Suriname' 'Swaziland' 'Sweden' 'Switzerland' 'Syria' 'Taiwan'\n",
      " 'Tajikistan' 'Tanzania' 'Thailand' 'Timor-Leste' 'Togo' 'Tonga'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan' 'Tuvalu' 'Uganda'\n",
      " 'Ukraine' 'United Arab Emirates' 'United Kingdom'\n",
      " 'United States of America' 'Uruguay' 'Uzbekistan' 'Vanuatu' 'Venezuela'\n",
      " 'Vietnam' 'West Bank and Gaza' 'Yemen' 'Zambia' 'Zimbabwe'] \n",
      "\n",
      "Series name:\n",
      " Country \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the series shape\n",
    "print(\"Series shape:\\n\", country_col.shape, \"\\n\")\n",
    "\n",
    "# Display the series index\n",
    "print(\"Series index:\\n\", country_col.index, \"\\n\")\n",
    "\n",
    "# Display the series values\n",
    "print(\"Series values:\\n\", country_col.values, \"\\n\")\n",
    "\n",
    "# Display the series name\n",
    "print(\"Series name:\\n\", country_col.name, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26c3ab-9ec9-4444-8166-8ed14f29bbd9",
   "metadata": {},
   "source": [
    "## Querying data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc80da-94cd-4e4d-9a33-943114370962",
   "metadata": {},
   "source": [
    "**Using the Quandl API, import the data**\n",
    "- Print the head() and tail()\n",
    "- Query the last value using the last date\n",
    "- Query the date with date strings in the YYYYMMDD format\n",
    "- Query with a Boolean, where the number of observations is greater than the mean number of observations\n",
    "- Query with a Boolean, where the number of sunspots is greater than the mean number of sunspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd26de5-17cf-4c32-9fa1-d5415334314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head 5:\n",
      "             Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "Date                                                                           \n",
      "1700-12-31                               8.3                             NaN   \n",
      "1701-12-31                              18.3                             NaN   \n",
      "1702-12-31                              26.7                             NaN   \n",
      "1703-12-31                              38.3                             NaN   \n",
      "1704-12-31                              60.0                             NaN   \n",
      "\n",
      "            Number of Observations  Definitive/Provisional Indicator  \n",
      "Date                                                                  \n",
      "1700-12-31                     NaN                               1.0  \n",
      "1701-12-31                     NaN                               1.0  \n",
      "1702-12-31                     NaN                               1.0  \n",
      "1703-12-31                     NaN                               1.0  \n",
      "1704-12-31                     NaN                               1.0  \n",
      "Tail 5:\n",
      "             Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "Date                                                                           \n",
      "2016-12-31                              39.8                             3.9   \n",
      "2017-12-31                              21.7                             2.5   \n",
      "2018-12-31                               7.0                             1.1   \n",
      "2019-12-31                               3.6                             0.5   \n",
      "2020-12-31                               8.8                             4.1   \n",
      "\n",
      "            Number of Observations  Definitive/Provisional Indicator  \n",
      "Date                                                                  \n",
      "2016-12-31                  9940.0                               1.0  \n",
      "2017-12-31                 11444.0                               1.0  \n",
      "2018-12-31                 12611.0                               1.0  \n",
      "2019-12-31                 12884.0                               1.0  \n",
      "2020-12-31                 14440.0                               1.0  \n"
     ]
    }
   ],
   "source": [
    "# Import the data using the Quandl API\n",
    "sunspots = quandl.get(\"SIDC/SUNSPOTS_A\")\n",
    "\n",
    "# Display first five results\n",
    "print(\"Head 5:\\n\", sunspots.head(5))\n",
    "\n",
    "# Display bottom five results\n",
    "print(\"Tail 5:\\n\", sunspots.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b14a0b9-8efa-43c3-a4dc-b9a57932b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last value:\n",
      " Yearly Mean Total Sunspot Number        8.8\n",
      "Yearly Mean Standard Deviation          4.1\n",
      "Number of Observations              14440.0\n",
      "Definitive/Provisional Indicator        1.0\n",
      "Name: 2020-12-31 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Query the last value using the last date in the dataset\n",
    "last_date = sunspots.index[-1]\n",
    "print(\"Last value:\\n\",sunspots.loc[last_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab47b2d2-9ec2-4740-b45f-70d7785c0941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values slice by date:\n",
      "             Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "Date                                                                           \n",
      "2002-12-31                             163.6                             9.8   \n",
      "2003-12-31                              99.3                             7.1   \n",
      "2004-12-31                              65.3                             5.9   \n",
      "2005-12-31                              45.8                             4.7   \n",
      "2006-12-31                              24.7                             3.5   \n",
      "2007-12-31                              12.6                             2.7   \n",
      "2008-12-31                               4.2                             2.5   \n",
      "2009-12-31                               4.8                             2.5   \n",
      "2010-12-31                              24.9                             3.4   \n",
      "2011-12-31                              80.8                             6.7   \n",
      "2012-12-31                              84.5                             6.7   \n",
      "2013-12-31                              94.0                             6.9   \n",
      "\n",
      "            Number of Observations  Definitive/Provisional Indicator  \n",
      "Date                                                                  \n",
      "2002-12-31                  6588.0                               1.0  \n",
      "2003-12-31                  7087.0                               1.0  \n",
      "2004-12-31                  6882.0                               1.0  \n",
      "2005-12-31                  7084.0                               1.0  \n",
      "2006-12-31                  6370.0                               1.0  \n",
      "2007-12-31                  6841.0                               1.0  \n",
      "2008-12-31                  6644.0                               1.0  \n",
      "2009-12-31                  6465.0                               1.0  \n",
      "2010-12-31                  6328.0                               1.0  \n",
      "2011-12-31                  6077.0                               1.0  \n",
      "2012-12-31                  5753.0                               1.0  \n",
      "2013-12-31                  5347.0                               1.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the date with the YYYYMMDD format\n",
    "print(\"Values slice by date:\\n\", sunspots[\"20020101\": \"20131231\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737bd59f-a5ab-4c88-808f-0dc92af73f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean selection:\n",
      "             Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "Date                                                                           \n",
      "1700-12-31                               NaN                             NaN   \n",
      "1701-12-31                               NaN                             NaN   \n",
      "1702-12-31                               NaN                             NaN   \n",
      "1703-12-31                               NaN                             NaN   \n",
      "1704-12-31                               NaN                             NaN   \n",
      "...                                      ...                             ...   \n",
      "2016-12-31                               NaN                             NaN   \n",
      "2017-12-31                               NaN                             NaN   \n",
      "2018-12-31                               NaN                             NaN   \n",
      "2019-12-31                               NaN                             NaN   \n",
      "2020-12-31                               NaN                             NaN   \n",
      "\n",
      "            Number of Observations  Definitive/Provisional Indicator  \n",
      "Date                                                                  \n",
      "1700-12-31                     NaN                               NaN  \n",
      "1701-12-31                     NaN                               NaN  \n",
      "1702-12-31                     NaN                               NaN  \n",
      "1703-12-31                     NaN                               NaN  \n",
      "1704-12-31                     NaN                               NaN  \n",
      "...                            ...                               ...  \n",
      "2016-12-31                  9940.0                               NaN  \n",
      "2017-12-31                 11444.0                               NaN  \n",
      "2018-12-31                 12611.0                               NaN  \n",
      "2019-12-31                 12884.0                               NaN  \n",
      "2020-12-31                 14440.0                               NaN  \n",
      "\n",
      "[321 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use boolean to find where number of observations is greater than the mean\n",
    "print(\"Boolean selection:\\n\", sunspots[sunspots > sunspots.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34c2e58-4688-443a-9b8c-61ad64bb7355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean selection with column label:\n",
      "             Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "Date                                                                           \n",
      "1981-12-31                             198.9                            13.1   \n",
      "1982-12-31                             162.4                            12.1   \n",
      "1983-12-31                              91.0                             7.6   \n",
      "1984-12-31                              60.5                             5.9   \n",
      "1985-12-31                              20.6                             3.7   \n",
      "1986-12-31                              14.8                             3.5   \n",
      "1987-12-31                              33.9                             3.7   \n",
      "1988-12-31                             123.0                             8.4   \n",
      "1989-12-31                             211.1                            12.8   \n",
      "1990-12-31                             191.8                            11.2   \n",
      "1991-12-31                             203.3                            12.7   \n",
      "1992-12-31                             133.0                             8.9   \n",
      "1993-12-31                              76.1                             5.8   \n",
      "1994-12-31                              44.9                             4.4   \n",
      "1995-12-31                              25.1                             3.7   \n",
      "1996-12-31                              11.6                             3.1   \n",
      "1997-12-31                              28.9                             3.6   \n",
      "1998-12-31                              88.3                             6.6   \n",
      "1999-12-31                             136.3                             9.3   \n",
      "2000-12-31                             173.9                            10.1   \n",
      "2001-12-31                             170.4                            10.5   \n",
      "2002-12-31                             163.6                             9.8   \n",
      "2003-12-31                              99.3                             7.1   \n",
      "2004-12-31                              65.3                             5.9   \n",
      "2005-12-31                              45.8                             4.7   \n",
      "2006-12-31                              24.7                             3.5   \n",
      "2007-12-31                              12.6                             2.7   \n",
      "2008-12-31                               4.2                             2.5   \n",
      "2009-12-31                               4.8                             2.5   \n",
      "2010-12-31                              24.9                             3.4   \n",
      "2011-12-31                              80.8                             6.7   \n",
      "2012-12-31                              84.5                             6.7   \n",
      "2013-12-31                              94.0                             6.9   \n",
      "2014-12-31                             113.3                             8.0   \n",
      "2015-12-31                              69.8                             6.4   \n",
      "2016-12-31                              39.8                             3.9   \n",
      "2017-12-31                              21.7                             2.5   \n",
      "2018-12-31                               7.0                             1.1   \n",
      "2019-12-31                               3.6                             0.5   \n",
      "2020-12-31                               8.8                             4.1   \n",
      "\n",
      "            Number of Observations  Definitive/Provisional Indicator  \n",
      "Date                                                                  \n",
      "1981-12-31                  3049.0                               1.0  \n",
      "1982-12-31                  3436.0                               1.0  \n",
      "1983-12-31                  4216.0                               1.0  \n",
      "1984-12-31                  5103.0                               1.0  \n",
      "1985-12-31                  5543.0                               1.0  \n",
      "1986-12-31                  5934.0                               1.0  \n",
      "1987-12-31                  6396.0                               1.0  \n",
      "1988-12-31                  6556.0                               1.0  \n",
      "1989-12-31                  6932.0                               1.0  \n",
      "1990-12-31                  7108.0                               1.0  \n",
      "1991-12-31                  6932.0                               1.0  \n",
      "1992-12-31                  7845.0                               1.0  \n",
      "1993-12-31                  8010.0                               1.0  \n",
      "1994-12-31                  8524.0                               1.0  \n",
      "1995-12-31                  8429.0                               1.0  \n",
      "1996-12-31                  7614.0                               1.0  \n",
      "1997-12-31                  7294.0                               1.0  \n",
      "1998-12-31                  6353.0                               1.0  \n",
      "1999-12-31                  6413.0                               1.0  \n",
      "2000-12-31                  5953.0                               1.0  \n",
      "2001-12-31                  6558.0                               1.0  \n",
      "2002-12-31                  6588.0                               1.0  \n",
      "2003-12-31                  7087.0                               1.0  \n",
      "2004-12-31                  6882.0                               1.0  \n",
      "2005-12-31                  7084.0                               1.0  \n",
      "2006-12-31                  6370.0                               1.0  \n",
      "2007-12-31                  6841.0                               1.0  \n",
      "2008-12-31                  6644.0                               1.0  \n",
      "2009-12-31                  6465.0                               1.0  \n",
      "2010-12-31                  6328.0                               1.0  \n",
      "2011-12-31                  6077.0                               1.0  \n",
      "2012-12-31                  5753.0                               1.0  \n",
      "2013-12-31                  5347.0                               1.0  \n",
      "2014-12-31                  5273.0                               1.0  \n",
      "2015-12-31                  8903.0                               1.0  \n",
      "2016-12-31                  9940.0                               1.0  \n",
      "2017-12-31                 11444.0                               1.0  \n",
      "2018-12-31                 12611.0                               1.0  \n",
      "2019-12-31                 12884.0                               1.0  \n",
      "2020-12-31                 14440.0                               1.0  \n"
     ]
    }
   ],
   "source": [
    "# Use boolean to find where number of sunspots is greater than the mean\n",
    "print(\"Boolean selection with column label:\\n\", sunspots[sunspots['Number of Observations'] > sunspots['Number of Observations'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6f71a-a60c-4ac7-ba5c-8569cd1fe501",
   "metadata": {},
   "source": [
    "## Statistics with Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df245f7-c190-4f0c-be9e-94804b51d2ac",
   "metadata": {},
   "source": [
    "**Using the Quandl API, import the data and run the following descriptive stats where Sunspots is not equal to NaN.**\n",
    " - Print the results of the describe function\n",
    " - Print the count of observations\n",
    " - Print the mad\n",
    " - Print the mean\n",
    " - Print the median\n",
    " - Print the Max\n",
    " - Print the Min\n",
    " - Print the Mode\n",
    " - Print the standard deviation\n",
    " - Print the variance\n",
    " - Print the Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6268721e-63f3-4867-8e40-ae5406903154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe        Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "count                        321.000000                      203.000000   \n",
      "mean                          78.517134                        7.892118   \n",
      "std                           62.091523                        3.866310   \n",
      "min                            0.000000                        0.500000   \n",
      "25%                           24.200000                        4.550000   \n",
      "50%                           65.300000                        7.600000   \n",
      "75%                          115.200000                       10.350000   \n",
      "max                          269.300000                       19.100000   \n",
      "\n",
      "       Number of Observations  Definitive/Provisional Indicator  \n",
      "count              203.000000                             321.0  \n",
      "mean              1691.857143                               1.0  \n",
      "std               2913.060813                               0.0  \n",
      "min                150.000000                               1.0  \n",
      "25%                365.000000                               1.0  \n",
      "50%                365.000000                               1.0  \n",
      "75%                366.000000                               1.0  \n",
      "max              14440.000000                               1.0   \n",
      "\n",
      "Non NaN observations Yearly Mean Total Sunspot Number    321\n",
      "Yearly Mean Standard Deviation      203\n",
      "Number of Observations              203\n",
      "Definitive/Provisional Indicator    321\n",
      "dtype: int64 \n",
      "\n",
      "MAD Yearly Mean Total Sunspot Number      51.020996\n",
      "Yearly Mean Standard Deviation         3.177068\n",
      "Number of Observations              2162.410978\n",
      "Definitive/Provisional Indicator       0.000000\n",
      "dtype: float64 \n",
      "\n",
      "Mean Yearly Mean Total Sunspot Number      78.517134\n",
      "Yearly Mean Standard Deviation         7.892118\n",
      "Number of Observations              1691.857143\n",
      "Definitive/Provisional Indicator       1.000000\n",
      "dtype: float64 \n",
      "\n",
      "Median Yearly Mean Total Sunspot Number     65.3\n",
      "Yearly Mean Standard Deviation        7.6\n",
      "Number of Observations              365.0\n",
      "Definitive/Provisional Indicator      1.0\n",
      "dtype: float64 \n",
      "\n",
      "Max Yearly Mean Total Sunspot Number      269.3\n",
      "Yearly Mean Standard Deviation         19.1\n",
      "Number of Observations              14440.0\n",
      "Definitive/Provisional Indicator        1.0\n",
      "dtype: float64 \n",
      "\n",
      "Min Yearly Mean Total Sunspot Number      0.0\n",
      "Yearly Mean Standard Deviation        0.5\n",
      "Number of Observations              150.0\n",
      "Definitive/Provisional Indicator      1.0\n",
      "dtype: float64 \n",
      "\n",
      "Mode    Yearly Mean Total Sunspot Number  Yearly Mean Standard Deviation  \\\n",
      "0                              18.3                             9.2   \n",
      "\n",
      "   Number of Observations  Definitive/Provisional Indicator  \n",
      "0                   365.0                               1.0   \n",
      "\n",
      "Standard Deviation Yearly Mean Total Sunspot Number      62.091523\n",
      "Yearly Mean Standard Deviation         3.866310\n",
      "Number of Observations              2913.060813\n",
      "Definitive/Provisional Indicator       0.000000\n",
      "dtype: float64 \n",
      "\n",
      "Variance Yearly Mean Total Sunspot Number    3.855357e+03\n",
      "Yearly Mean Standard Deviation      1.494835e+01\n",
      "Number of Observations              8.485923e+06\n",
      "Definitive/Provisional Indicator    0.000000e+00\n",
      "dtype: float64 \n",
      "\n",
      "Skewness Yearly Mean Total Sunspot Number    0.814781\n",
      "Yearly Mean Standard Deviation      0.533409\n",
      "Number of Observations              2.099601\n",
      "Definitive/Provisional Indicator    0.000000\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the data using the Quandl API\n",
    "sunspots = quandl.get(\"SIDC/SUNSPOTS_A\")\n",
    "\n",
    "# Display results for describe function\n",
    "print(\"Describe\", sunspots.describe(),\"\\n\")\n",
    "\n",
    "# Display count of observations\n",
    "print(\"Non NaN observations\", sunspots.count(),\"\\n\")\n",
    "\n",
    "# No attribute for Mean Absolute Deviation (MAD) with DataFrame\n",
    "# Define function to calculate MAD\n",
    "def calculate_mad(series):\n",
    "    mean_value = series.mean()\n",
    "    mad_value = np.mean(np.abs(series - mean_value))\n",
    "    return mad_value\n",
    "\n",
    "# Define applicable data types\n",
    "mad_values = sunspots.select_dtypes(include=['float64']).apply(calculate_mad)\n",
    "# Display the MAD\n",
    "print(\"MAD\", (mad_values), \"\\n\")\n",
    "\n",
    "# Display the median\n",
    "print(\"Mean\", sunspots.mean(),\"\\n\")\n",
    "\n",
    "# Display the median\n",
    "print(\"Median\", sunspots.median(),\"\\n\")\n",
    "\n",
    "# Display the Max\n",
    "print(\"Max\", sunspots.max(),\"\\n\")\n",
    "\n",
    "# Display the Min\n",
    "print(\"Min\", sunspots.min(),\"\\n\")\n",
    "\n",
    "# Display the mode\n",
    "print(\"Mode\", sunspots.mode(),\"\\n\")\n",
    "\n",
    "# Display the standard deviation\n",
    "print(\"Standard Deviation\", sunspots.std(),\"\\n\")\n",
    "\n",
    "# Display the variance\n",
    "print(\"Variance\", sunspots.var(),\"\\n\")\n",
    "\n",
    "# Display the skewness\n",
    "print(\"Skewness\", sunspots.skew(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26014ae9-a192-47d6-93c5-4070ce500fff",
   "metadata": {},
   "source": [
    "## Data Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc73efc-0f85-40fe-a4f2-db130462ae63",
   "metadata": {},
   "source": [
    "**Using the NumPy random data generator, create a data frame with the following columns (Weather, Food Price, and Number)(pg. 70 of your text).**\n",
    " - Group the data by the weather column and then create a function to iterate through the groups (you should have two groups after, for hot and cold)\n",
    " - Your function/variable that you created (weather_group)can be used for aggregation methods - print the first row, the last row, and the mean for each group\n",
    " - Create another group, on Food (so you would have Weather and Food)\n",
    " - Using the new groups - use the NumPy function agg() to find the mean and median number and prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6da0919f-f12e-4834-b3d5-9b1af4208100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Weather       Food     Price  Number\n",
      "0    cold       soup  3.745401       8\n",
      "1     hot       soup  9.507143       8\n",
      "2    cold   icecream  7.319939       8\n",
      "3     hot  chocolate  5.986585       8\n",
      "4    cold   icecream  1.560186       8\n",
      "5     hot   icecream  1.559945       8\n",
      "6    cold       soup  0.580836       8\n"
     ]
    }
   ],
   "source": [
    "# Initialize the random generator\n",
    "seed(42)\n",
    "\n",
    "# Load the dataframe\n",
    "df = pd.DataFrame({'Weather' : ['cold', 'hot', 'cold', 'hot',\n",
    "   'cold', 'hot', 'cold'],\n",
    "   'Food' : ['soup', 'soup', 'icecream', 'chocolate',\n",
    "   'icecream', 'icecream', 'soup'],\n",
    "   'Price' : 10 * rand(7), 'Number' : randint(1, 9)})\n",
    "\n",
    "# Display results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40069937-a14b-4152-a625-9dda6273daf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Group: cold\n",
      "First row:\n",
      "Weather        cold\n",
      "Food           soup\n",
      "Price      3.745401\n",
      "Number            8\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Last row:\n",
      "Weather        cold\n",
      "Food           soup\n",
      "Price      0.580836\n",
      "Number            8\n",
      "Name: 6, dtype: object\n",
      "\n",
      "Mean values:\n",
      "Price     3.301591\n",
      "Number    8.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Weather Group: hot\n",
      "First row:\n",
      "Weather         hot\n",
      "Food           soup\n",
      "Price      9.507143\n",
      "Number            8\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Last row:\n",
      "Weather         hot\n",
      "Food       icecream\n",
      "Price      1.559945\n",
      "Number            8\n",
      "Name: 5, dtype: object\n",
      "\n",
      "Mean values:\n",
      "Price     5.684558\n",
      "Number    8.000000\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the function to iterate through groups\n",
    "def weather_group(name, group):\n",
    "    print(f\"Weather Group: {name}\")\n",
    "    print(\"First row:\")\n",
    "    print(group.iloc[0])\n",
    "    print(\"\\nLast row:\")\n",
    "    print(group.iloc[-1])\n",
    "    print(\"\\nMean values:\")\n",
    "    print(group.mean(numeric_only=True))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Group by Weather\n",
    "weather_groups = df.groupby('Weather')\n",
    "\n",
    "# Apply function to each group\n",
    "for name, group in weather_groups:\n",
    "    weather_group(name, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b2edd9-2f4d-4374-9246-be76ad7f6037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WF Groups {('cold', 'icecream'): [2, 4], ('cold', 'soup'): [0, 6], ('hot', 'chocolate'): [3], ('hot', 'icecream'): [5], ('hot', 'soup'): [1]}\n"
     ]
    }
   ],
   "source": [
    "# Define the new group\n",
    "wf_group = df.groupby(['Weather', 'Food'])\n",
    "\n",
    "# Display the results\n",
    "print(\"WF Groups\", wf_group.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caec1912-6330-4971-b954-a9554bfc0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WF Aggregated\n",
      "                       Price           Number       \n",
      "                       mean    median   mean median\n",
      "Weather Food                                       \n",
      "cold    icecream   4.440063  4.440063    8.0    8.0\n",
      "        soup       2.163119  2.163119    8.0    8.0\n",
      "hot     chocolate  5.986585  5.986585    8.0    8.0\n",
      "        icecream   1.559945  1.559945    8.0    8.0\n",
      "        soup       9.507143  9.507143    8.0    8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thefli0\\AppData\\Local\\Temp\\ipykernel_3048\\2030833496.py:2: FutureWarning: The provided callable <function mean at 0x0000020AC073ACA0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  print(\"WF Aggregated\\n\", wf_group.agg([np.mean, np.median]))\n",
      "C:\\Users\\thefli0\\AppData\\Local\\Temp\\ipykernel_3048\\2030833496.py:2: FutureWarning: The provided callable <function median at 0x0000020AC0877D80> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  print(\"WF Aggregated\\n\", wf_group.agg([np.mean, np.median]))\n",
      "C:\\Users\\thefli0\\AppData\\Local\\Temp\\ipykernel_3048\\2030833496.py:2: FutureWarning: The provided callable <function mean at 0x0000020AC073ACA0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  print(\"WF Aggregated\\n\", wf_group.agg([np.mean, np.median]))\n"
     ]
    }
   ],
   "source": [
    "# Display the results for the mean and median with new groups and the agg() function\n",
    "print(\"WF Aggregated\\n\", wf_group.agg([np.mean, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9782d-aa22-419c-a567-bef66e0b0256",
   "metadata": {},
   "source": [
    "## Concatenating and appending DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ceb2e-2a96-4414-9bc5-0dbfbc61d30c",
   "metadata": {},
   "source": [
    "**Using the dataframe you created previously, select the first 3 rows.**\n",
    " - Using the concat function from pandas, put the 3 rows that you selected back with the original dataframe\n",
    " - Using the append function, take those 3 rows and the last 2 rows of the original DataFrame and bring them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98716b09-6cfb-42fe-993e-3ae907328590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df :3\n",
      "   Weather      Food     Price  Number\n",
      "0    cold      soup  3.745401       8\n",
      "1     hot      soup  9.507143       8\n",
      "2    cold  icecream  7.319939       8\n"
     ]
    }
   ],
   "source": [
    "# Display the first 3 rows\n",
    "print(\"df :3\\n\", df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05e9fc3f-a8af-48c6-97e0-caa087e81481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate Back\n",
      "   Weather       Food     Price  Number\n",
      "0    cold       soup  3.745401       8\n",
      "1     hot       soup  9.507143       8\n",
      "2    cold   icecream  7.319939       8\n",
      "3     hot  chocolate  5.986585       8\n",
      "4    cold   icecream  1.560186       8\n",
      "5     hot   icecream  1.559945       8\n",
      "6    cold       soup  0.580836       8\n"
     ]
    }
   ],
   "source": [
    "# Use the concat function to put the first 3 rows back\n",
    "print(\"Concatenate Back\\n\", pd.concat([df[:3], df[3:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e6a239-0948-466b-8ebf-48d4282603dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending rows\n",
      "   Weather      Food     Price  Number\n",
      "0    cold      soup  3.745401       8\n",
      "1     hot      soup  9.507143       8\n",
      "2    cold  icecream  7.319939       8\n",
      "3     hot  icecream  1.559945       8\n",
      "4    cold      soup  0.580836       8\n"
     ]
    }
   ],
   "source": [
    "# Use append to bring together the first 3 rows with the last 2 rows\n",
    "append_rows = pd.concat([df.head(3), df.tail(2)], ignore_index=True)\n",
    "print(\"Appending rows\\n\", append_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ddbce-0328-45ca-8451-598b4f712c26",
   "metadata": {},
   "source": [
    "## Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261437eb-2268-40ea-9f38-117b02cb33e4",
   "metadata": {},
   "source": [
    "**Using the two csv files dtest.csv and tips.csv, we will bring together two datasets, also known as a join.**\n",
    " - Using the merge() function, bring dtest and tips together on the \"EmpNr\" column and print the results\n",
    " - Using the join() function, query both files and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51807461-10b9-4766-bf9e-3c5adb1b5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dests\n",
      "    EmpNr       Dest\n",
      "0      5  The Hague\n",
      "1      3  Amsterdam\n",
      "2      9  Rotterdam\n",
      "Tips\n",
      "    EmpNr  Amount\n",
      "0      5    10.0\n",
      "1      9     5.0\n",
      "2      7     2.5\n",
      "Merge() on key\n",
      "    EmpNr       Dest  Amount\n",
      "0      5  The Hague    10.0\n",
      "1      9  Rotterdam     5.0\n",
      "Dests join() tips\n",
      "    EmpNrDest       Dest  EmpNrTips  Amount\n",
      "0          5  The Hague          5    10.0\n",
      "1          3  Amsterdam          9     5.0\n",
      "2          9  Rotterdam          7     2.5\n",
      "Inner join with merge()\n",
      "    EmpNr       Dest  Amount\n",
      "0      5  The Hague    10.0\n",
      "1      9  Rotterdam     5.0\n",
      "Outer join\n",
      "    EmpNr       Dest  Amount\n",
      "0      5  The Hague    10.0\n",
      "1      3  Amsterdam     NaN\n",
      "2      9  Rotterdam     5.0\n",
      "3      7        NaN     2.5\n"
     ]
    }
   ],
   "source": [
    "# Join the two datasets together\n",
    "dests = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\dest.csv')\n",
    "print(\"Dests\\n\", dests)\n",
    "\n",
    "tips = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\tips.csv')\n",
    "print(\"Tips\\n\", tips)\n",
    "\n",
    "# Use the merge function to bring files together on the 'EmpNr' column\n",
    "print(\"Merge() on key\\n\", pd.merge(dests, tips, on='EmpNr'))\n",
    "# Display the results\n",
    "print(\"Dests join() tips\\n\", dests.join(tips, lsuffix='Dest', rsuffix='Tips'))\n",
    "\n",
    "# Display the results of the joins\n",
    "print(\"Inner join with merge()\\n\", pd.merge(dests, tips, how='inner'))\n",
    "print(\"Outer join\\n\", pd.merge(dests, tips, how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa58d98-650c-4866-aa2f-6a6868ea9f62",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e642d8-6096-4662-a455-30bcf366f50b",
   "metadata": {},
   "source": [
    "**Using the WHO_first9cols.csv file, select the first 3 rows, including the headers for these two columns Country & Net primary school enrollment ratio male (%)**\n",
    " - Check for missing values\n",
    " - Count the number of NaN values\n",
    " - Print any non-missing values\n",
    " - Replace the missing values with a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "650983bc-a45e-4af2-b172-1f7420dbac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values\n",
      "    Country  Net primary school enrolment ratio male (%)\n",
      "0    False                                         True\n",
      "1    False                                        False\n",
      "Total Null Values\n",
      " Country                                        0\n",
      "Net primary school enrolment ratio male (%)    1\n",
      "dtype: int64\n",
      "Not Null Values\n",
      "    Country  Net primary school enrolment ratio male (%)\n",
      "0     True                                        False\n",
      "1     True                                         True\n",
      "Zero filled\n",
      "        Country  Net primary school enrolment ratio male (%)\n",
      "0  Afghanistan                                          0.0\n",
      "1      Albania                                         94.0\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file as the dataframe\n",
    "df = read_csv(r\"C:\\Users\\thefli0\\Downloads\\WHO_first9cols.csv\")\n",
    "\n",
    "# Select first 3 rows of country and Net primary school enrollment ratio male (%)\n",
    "df = df[['Country', df.columns[-2]]][:2]\n",
    "\n",
    "# Display count of missing values\n",
    "print(\"Null Values\\n\", pd.isnull(df))\n",
    "\n",
    "# Display count of NaN values\n",
    "print(\"Total Null Values\\n\", pd.isnull(df).sum())\n",
    "\n",
    "# Display count of non-missing values\n",
    "print(\"Not Null Values\\n\", df.notnull())\n",
    "\n",
    "# Replace any missing values\n",
    "print(\"Zero filled\\n\", df.fillna(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
