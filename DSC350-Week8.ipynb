{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd9486b-74e0-4bf2-8abb-3c4ad95e083f",
   "metadata": {},
   "source": [
    "# DSC350 - Week 8 - Exercise 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73932861-70a0-4820-8eae-d2690e9cd65b",
   "metadata": {},
   "source": [
    "We begin the exercises this week by importing the necessary libraries and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0590df83-d4ae-4576-8e88-03026d4b4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tempfile import NamedTemporaryFile\n",
    "from os.path import getsize\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b16df8c2-c10b-4486-ba68-5f091a298cd8",
   "metadata": {},
   "source": [
    "============================================\n",
    "; Title: Assignment 8.2\n",
    "; Author: Armando Fandango\n",
    "; Date: 24 July 2024\n",
    "; Modified By: Tyler Heflin\n",
    "; Description: This program demonstrates the use of Python for various\n",
    "; tasks related to retrieving, processing, and storing data.\n",
    ";=========================================== */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b042a66-aee1-46df-b7f9-7f1699cc0a1d",
   "metadata": {},
   "source": [
    "## Chapter 5 : Retrieving, Processing, and Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4135d015-3be3-43e1-97c3-3d442f9164c1",
   "metadata": {},
   "source": [
    "## Writing CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b3650-4969-4e7d-bd5d-12d5b4a879dd",
   "metadata": {},
   "source": [
    "**1. Generate a 3X4 NumPy array after seeing the random generator.**\n",
    " - a) Save the array as a CSV named \"np.csv\".\n",
    " - b) View the np field with the cat command (doesn't need to be included in code, just so you can verify the file looks correct).\n",
    " - c) Create a DataFrame from the file and print the results.\n",
    " - d) Write the DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f693902-85d1-4826-9025-abfd6dcfa2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49671415 -0.1382643   0.64768854  1.52302986]\n",
      " [-0.23415337 -0.23413696  1.57921282  0.76743473]\n",
      " [-0.46947439  0.54256004         nan -0.46572975]]\n",
      "          0         1         2         3\n",
      "0  0.496714 -0.138264  0.647689  1.523030\n",
      "1 -0.234153 -0.234137  1.579213  0.767435\n",
      "2 -0.469474  0.542560       NaN -0.465730\n"
     ]
    }
   ],
   "source": [
    "# Use NumPy random generator\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a 3X4 array\n",
    "a = np.random.randn(3, 4)\n",
    "a[2][2] = np.nan\n",
    "print(a)\n",
    "# Save array as CSV with defined file name\n",
    "np.savetxt('np.csv', a, fmt='%.2f', delimiter=',', header=\" #1, #2,  #3,  #4\")\n",
    "# Create dataframe from file and display results\n",
    "df = pd.DataFrame(a)\n",
    "print(df)\n",
    "# Write newly created dataframe to CSV file\n",
    "df.to_csv('pd.csv', float_format='%.2f', na_rep=\"NAN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b20645-f0e1-41c6-8f7f-10680fca1037",
   "metadata": {},
   "source": [
    "## Comparing binary .npy format and pickle format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d20dfa-8ce6-4775-8730-4cf380740173",
   "metadata": {},
   "source": [
    "**2. Generate a 365X4 NumPy array with random values.**\n",
    " - a) Store the array in a CSV file and check its size.\n",
    " - b) Save the array in the NumPy format, load the array, check its shape and the size of the file.\n",
    " - c) Create a DataFrame from this array you have created and write it to a pickle, then retrieve it from the pickle.\n",
    " - d) Print the size of the pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524ef357-89d7-4cc2-90a8-7825f8ea821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file size: 37562 bytes\n",
      "Array shape: (365, 4)\n",
      "NumPy file size: 11808 bytes\n",
      "Pickle file size: 12239 bytes\n"
     ]
    }
   ],
   "source": [
    "# Use NumPy to generate a 365X4 array with random values\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(365, 4)\n",
    "\n",
    "# Store array as CSV and check size\n",
    "with NamedTemporaryFile(delete=False, suffix='.csv') as tmp_csv:\n",
    "    np.savetxt(tmp_csv.name, a, delimiter=',')\n",
    "    csv_size = getsize(tmp_csv.name)\n",
    "\n",
    "print(f\"CSV file size: {csv_size} bytes\")\n",
    "\n",
    "# Save array in NumPy format\n",
    "with NamedTemporaryFile(delete=False, suffix='.npy') as tmp_npy:\n",
    "    np.save(tmp_npy.name, a)\n",
    "    npy_size = getsize(tmp_npy.name)\n",
    "\n",
    "# Load array from NumPy and check its shape/file size\n",
    "loaded_array = np.load(tmp_npy.name)\n",
    "array_shape = loaded_array.shape\n",
    "\n",
    "print(f\"Array shape: {array_shape}\")\n",
    "print(f\"NumPy file size: {npy_size} bytes\")\n",
    "\n",
    "# Create dataframe from the array\n",
    "df = pd.DataFrame(loaded_array)\n",
    "\n",
    "# Write dataframe to pickle and retrieve it\n",
    "with NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_pkl:\n",
    "    df.to_pickle(tmp_pkl.name)\n",
    "    pickle_size = getsize(tmp_pkl.name)\n",
    "\n",
    "# Load dataframe from pickle\n",
    "loaded_df = pd.read_pickle(tmp_pkl.name)\n",
    "\n",
    "# Display results\n",
    "print(f\"Pickle file size: {pickle_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b8863-3e10-4948-b131-2f085590c4d3",
   "metadata": {},
   "source": [
    "## Reading and writing to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919acbc-c76d-4b6e-a871-93a61c337925",
   "metadata": {},
   "source": [
    "**3. Using the array created in #2, create an excel file with this data.**\n",
    " - a) After that is complete, create a dataframe from the excel.\n",
    " - b) Print your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd8a561-4243-4020-984d-b82e95e78927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3\n",
      "0    0.496714 -0.138264  0.647689  1.523030\n",
      "1   -0.234153 -0.234137  1.579213  0.767435\n",
      "2   -0.469474  0.542560 -0.463418 -0.465730\n",
      "3    0.241962 -1.913280 -1.724918 -0.562288\n",
      "4   -1.012831  0.314247 -0.908024 -1.412304\n",
      "..        ...       ...       ...       ...\n",
      "360  0.662881  1.173474  0.181022 -1.296832\n",
      "361  0.399688 -0.651357 -0.528617  0.586364\n",
      "362  1.238283  0.021272  0.308833  1.702215\n",
      "363  0.240753  2.601683  0.565510 -1.760763\n",
      "364  0.753342  0.381158  1.289753  0.673181\n",
      "\n",
      "[365 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create Excel file\n",
    "with NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_excel:\n",
    "    df.to_excel(tmp_excel.name, index=False)\n",
    "    excel_file_path = tmp_excel.name\n",
    "\n",
    "# Create dataframe from Excel file and display results\n",
    "df_from_excel = pd.read_excel(excel_file_path)\n",
    "print(df_from_excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c99a0a-3d20-4f23-b6aa-695d9dd32c3e",
   "metadata": {},
   "source": [
    "## Using REST and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99114b9b-0369-496f-bd46-4784298060fd",
   "metadata": {},
   "source": [
    "**4. Using this JSON string, parse a JSON string with the loads() function.**\n",
    "<br>\n",
    "<br>\n",
    "'{\"country\":\"Netherlands\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"ips\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}'\n",
    "<br>\n",
    " - a) Print the values for the \"Country\" column.\n",
    " - b) Overwrite the value for Netherlands with the value of your choice.\n",
    " - c) Print your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188280e7-f44c-47ed-8262-1e93b81dbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Netherlands\n",
      "{\"country\": \"Brazil\", \"dma_code\": \"0\", \"timezone\": \"Europe/Amsterdam\", \"area_code\": \"0\", \"ip\": \"46.19.37.108\", \"asn\": \"AS196752\", \"continent_code\": \"EU\", \"isp\": \"Tilaa V.O.F.\", \"longitude\": 5.75, \"latitude\": 52.5, \"country_code\": \"NL\", \"country_code3\": \"NLD\"}\n"
     ]
    }
   ],
   "source": [
    "# Define JSON string\n",
    "json_str = '{\"country\":\"Netherlands\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}'\n",
    "\n",
    "# Parse string with the loads() function\n",
    "data = json.loads(json_str)\n",
    "# Print values for \"Country\" column\n",
    "print(\"Country\", data[\"country\"])\n",
    "# Overwrite value for Netherlands with different country]\n",
    "data[\"country\"] = \"Brazil\"\n",
    "# Display results\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57838338-501b-4f54-b502-3defadc656c0",
   "metadata": {},
   "source": [
    "**5. Using the Pandas read_json() function, we can either create a pandas Series or DataFrame - taking the JSON string from #4, create a series.**\n",
    " - a) Change the country value again to your choice and convert the Pandas Series to a JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b410936-5aba-4187-be6b-5e7088178d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series\n",
      " country                Netherlands\n",
      "dma_code                         0\n",
      "timezone          Europe/Amsterdam\n",
      "area_code                        0\n",
      "ip                    46.19.37.108\n",
      "asn                       AS196752\n",
      "continent_code                  EU\n",
      "isp                   Tilaa V.O.F.\n",
      "longitude                     5.75\n",
      "latitude                      52.5\n",
      "country_code                    NL\n",
      "country_code3                  NLD\n",
      "dtype: object\n",
      "\n",
      "Revised Series\n",
      " {\"country\":\"Brazil\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}\n"
     ]
    }
   ],
   "source": [
    "# Define JSON string\n",
    "json_str = '{\"country\":\"Netherlands\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}'\n",
    "\n",
    "# Use read_json() function to create a series\n",
    "data = pd.read_json(json_str, typ='series')\n",
    "print(\"Pandas Series\\n\", data)\n",
    "\n",
    "# Change value previously chosen\n",
    "data[\"country\"] = \"Brazil\"\n",
    "# Convert series to JSON string\n",
    "print(\"\\nRevised Series\\n\", data.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e156864-96d7-48ae-8650-4dc4728e887a",
   "metadata": {},
   "source": [
    "## Parsing HTML with Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32075757-f4ee-44f2-9721-482e8b816037",
   "metadata": {},
   "source": [
    "**6. Starting on page 124 - follow along with the BeautifulSoup exercise to scrape data from the HTML page included in the GitHub repo. This exercise is great practice for your Term Project Milestone 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f53ed59-4c10-4e73-b128-53428bde392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First div\n",
      " <div class=\"tile\">\n",
      "<h4>Development</h4>\n",
      "     0.10.1 - July 2014<br/>\n",
      "</div>\n",
      "First div class ['tile']\n",
      "First dfn text Quare attende, quaeso.\n",
      "Link text loripsum.net URL http://loripsum.net/\n",
      "Link text Poterat autem inpune; URL http://loripsum.net/\n",
      "Link text Is es profecto tu. URL http://loripsum.net/\n",
      "0 ['\\n', <h4>Development</h4>, '\\n     0.10.1 - July 2014', <br/>, '\\n']\n",
      "1 ['\\n', <h4>Official Release</h4>, '\\n     0.10.0 June 2014', <br/>, '\\n']\n",
      "2 ['\\n', <h4>Previous Release</h4>, '\\n     0.09.1 June 2013', <br/>, '\\n']\n",
      "Official Version 0.10.0 June 2014\n",
      "# elements with class 3\n",
      "# Tile classes 2\n",
      "# Divs with class containing tile 3\n",
      "Using CSS selector\n",
      " [<div class=\"notile\">\n",
      "<h4>Previous Release</h4>\n",
      "     0.09.1 June 2013<br/>\n",
      "</div>]\n",
      "Selecting ordered list list items\n",
      " [<li>Cur id non ita fit?</li>, <li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n",
      "Second list item in ordered list [<li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n",
      "Searching for text string ['\\n     0.10.1 - July 2014', '\\n     0.10.0 June 2014']\n"
     ]
    }
   ],
   "source": [
    "# Define HTML page from repo\n",
    "soup = BeautifulSoup(open(r'C:\\Users\\thefli0\\Downloads\\loremIpsum.html'),\"lxml\")\n",
    "\n",
    "print(\"First div\\n\", soup.div)\n",
    "print(\"First div class\", soup.div['class'])\n",
    "\n",
    "print(\"First dfn text\", soup.dl.dt.dfn.text)\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "   print(\"Link text\", link.string, \"URL\", link.get('href'))\n",
    "\n",
    "# Omitting find_all\n",
    "for i, div in enumerate(soup('div')):\n",
    "   print(i, div.contents)\n",
    "\n",
    "\n",
    "#Div with id=official\n",
    "official_div = soup.find_all(\"div\", id=\"official\")\n",
    "print(\"Official Version\", official_div[0].contents[2].strip())\n",
    "\n",
    "print(\"# elements with class\", len(soup.find_all(class_=True)))\n",
    "\n",
    "tile_class = soup.find_all(\"div\", class_=\"tile\")\n",
    "print(\"# Tile classes\", len(tile_class))\n",
    "\n",
    "print(\"# Divs with class containing tile\", len(soup.find_all(\"div\", class_=re.compile(\"tile\"))))\n",
    "\n",
    "print(\"Using CSS selector\\n\", soup.select('div.notile'))\n",
    "print(\"Selecting ordered list list items\\n\", soup.select(\"ol > li\")[:2])\n",
    "print(\"Second list item in ordered list\", soup.select(\"ol > li:nth-of-type(2)\"))\n",
    "\n",
    "print(\"Searching for text string\", soup.find_all(text=re.compile(\"2014\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
