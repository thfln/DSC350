{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc42f41f-b555-4373-acf4-9bca7df5379f",
   "metadata": {},
   "source": [
    "# DSC350 - Term Project - Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa901521-2adc-4fd0-86d7-acbeb59e3b7c",
   "metadata": {},
   "source": [
    "**Connecting to an API/Pulling in the Data and Cleaning/Formatting** <br>\n",
    "Perform at least 5 data transformation and/or cleansing steps to your API data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb0e5d84-b424-4065-b48f-26c2650adbff",
   "metadata": {},
   "source": [
    "============================================\n",
    "; Title: Term Project - Milestone 2\n",
    "; Author: API-Football\n",
    "; Date: 10 July 2024\n",
    "; Modified By: Tyler Heflin\n",
    "; Description: This program demonstrates the use of Python for \n",
    "; modification and transformations to API data.\n",
    ";=========================================== */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e5dbb-cb68-4696-a80d-2e60ad1924c3",
   "metadata": {},
   "source": [
    "We begin the assignment by importing the necessary libraries for completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c8643e-3562-4a0e-b098-2f9ef2dea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9571364-6319-41db-bc49-5ce6abce204e",
   "metadata": {},
   "source": [
    "## Perform Request-Response Procedures on an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0820d18-ad5d-4545-b34c-b4a64f71f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the headers for the API\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"xXxXxXxXxXxXxXxXxxxXxXxXxX\",\n",
    "\t\"x-rapidapi-host\": \"api-football-v1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Define the endpoints for the API\n",
    "url1 = \"https://api-football-v1.p.rapidapi.com/v3/players\"\n",
    "url2 = \"https://api-football-v1.p.rapidapi.com/v3/leagues\"\n",
    "\n",
    "# Define the parameters for the players endpoint\n",
    "params_players = {\n",
    "    \"league\": \"253\",\n",
    "    \"season\": \"2023\"\n",
    "}\n",
    "\n",
    "# Define the parameters for the leagues endpoint\n",
    "params_leagues = {\n",
    "    \"id\": \"253\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929dbc5f-48b3-4052-912c-c710fe99ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a funtion to verify JSON format from API\n",
    "def format_json(response):\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError as e:\n",
    "        print(\"Response is not in JSON format:\", e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662e23e0-0a3e-4cb2-8fab-b8dfff55690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from 'players' endpoint\n",
    "response_players = requests.get(url1, headers=headers, params=params_players, verify=False)\n",
    "players_data = format_json(response_players)\n",
    "\n",
    "# Fetch data from 'leagues' endpoint\n",
    "response_leagues = requests.get(url2, headers=headers, params=params_leagues, verify=False)\n",
    "leagues_data = format_json(response_leagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1345c2-f99d-4922-883a-aaa251b2c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to file.\n"
     ]
    }
   ],
   "source": [
    "# Combine data into a DataFrame\n",
    "if players_data and leagues_data:\n",
    "    players_df = pd.json_normalize(players_data['response'])\n",
    "    leagues_df = pd.json_normalize(leagues_data['response'])\n",
    "\n",
    "    # Merge the DataFrames\n",
    "    combined_df = pd.concat([players_df, leagues_df], axis=1)\n",
    "    # Export newly created DataFrame\n",
    "    combined_df.to_csv(r'C:\\Users\\thefli0\\Downloads\\combined_data.csv', index=False)\n",
    "    print(\"Data successfully exported to file.\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch data in correct format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550deff1-05cb-42ab-ae0f-243717f2a9bf",
   "metadata": {},
   "source": [
    "## Load the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a437b02-a5b2-4b94-9b03-015a22a94924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\thefli0\\Downloads\\combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58cf00-f9da-4494-814c-3e135dd2015d",
   "metadata": {},
   "source": [
    "## Remove Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a334c99-1703-4236-a3b5-ac6378ac8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to be removed for cleaner dataset\n",
    "columns_to_drop = ['player.injured', 'player.photo', 'seasons', 'league.id', 'league.type', 'league.logo', \n",
    "                   'country.name', 'country.code', 'country.flag']\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368d3b8-e080-4f41-a2a7-8d5e7d5d4505",
   "metadata": {},
   "source": [
    "## Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5bee86-864e-4081-8039-d0f4a2e094db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be changed and what the new headers will be\n",
    "df = df.rename(columns={\n",
    "    'statistics': 'player_stats',\n",
    "    'player.id': 'player_id_num',\n",
    "    'player.name': 'player_full_name',\n",
    "    'player.firstname': 'player_first_name',\n",
    "    'player.lastname': 'player_last_name',\n",
    "    'player.age': 'age',\n",
    "    'player.birth.date': 'player_birthdate',\n",
    "    'player.birth.place': 'place_of_birth',\n",
    "    'player.birth.country': 'birth_country',\n",
    "    'player.nationality': 'nationality',\n",
    "    'player.height': 'height',\n",
    "    'player.weight': 'weight'\n",
    "})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18439d00-d47b-4b91-8fec-b2706efda986",
   "metadata": {},
   "source": [
    "## Change Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04bbc272-744e-4a22-b5fc-b22571db7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format to standard for dates\n",
    "if 'player_birthdate' in df.columns:\n",
    "    df['player_birthdate'] = pd.to_datetime(df['player_birthdate'], errors='coerce').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87232cc2-c93a-4c7f-9d38-eb0959121bc1",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c876b79d-c144-4d5f-9f40-7ac24f7f7920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to fill missing values with 'NULL'\n",
    "df = df.fillna('NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da047475-a9e2-4ef1-a329-e4b030dbb363",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ac23d5-fd1c-4ace-9f87-8af3a78821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cleansing of duplicates for unique ID number\n",
    "df = df.drop_duplicates(subset='player_id_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9843388-61e8-4529-a935-c2709f838ae2",
   "metadata": {},
   "source": [
    "## Write to New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780576b3-92bf-49b2-8c5e-5f2cd0e84c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and transformation complete. New file is saved to 'cleaned_combined_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Export the newly cleaned data\n",
    "df.to_csv(r'C:\\Users\\thefli0\\Downloads\\cleaned_combined_data.csv', index=False)\n",
    "\n",
    "print(\"Data cleaning and transformation complete. New file is saved to 'cleaned_combined_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
